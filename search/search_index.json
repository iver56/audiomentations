{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Audiomentations documentation","text":"<p>Audiomentations is a Python library for audio data augmentation, built to be fast and easy to use - its API is inspired by albumentations. It's useful for making audio deep learning models work well in the real world, not just in the lab. Audiomentations runs on CPU, supports mono audio and multichannel audio and integrates well in training pipelines, such as those built with TensorFlow/Keras or PyTorch. It has helped users achieve world-class results in Kaggle competitions and is trusted by companies building next-generation audio products with AI.</p> <p>Need a Pytorch-specific alternative with GPU support? Check out torch-audiomentations!</p>"},{"location":"#setup","title":"Setup","text":"<p><code>pip install audiomentations</code></p>"},{"location":"#optional-requirements","title":"Optional requirements","text":"<p>Some features have extra dependencies. Extra python package dependencies can be installed by running</p> <p><code>pip install audiomentations[extras]</code></p> Feature Extra dependencies <code>Limiter</code> <code>numpy-audio-limiter</code> <code>LoudnessNormalization</code> <code>loudness</code> <code>Mp3Compression</code> <code>fast-mp3-augment</code> <code>RoomSimulator</code> <code>pyroomacoustics</code> <p>Note: <code>ffmpeg</code> can be installed via e.g. conda or from the official ffmpeg download page.</p>"},{"location":"#usage-example","title":"Usage example","text":""},{"location":"#waveform","title":"Waveform","text":"<pre><code>from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\nimport numpy as np\n\naugment = Compose([\n    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n    Shift(p=0.5),\n])\n\n# Generate 2 seconds of dummy audio for the sake of example\nsamples = np.random.uniform(low=-0.2, high=0.2, size=(32000,)).astype(np.float32)\n\n# Augment/transform/perturb the audio data\naugmented_samples = augment(samples=samples, sample_rate=16000)\n</code></pre>"},{"location":"#waveform-transforms","title":"Waveform transforms","text":"<p>For a list and explanation of all waveform transforms, see Waveform transforms in the menu.</p> <p>Waveform transforms can be visualized (for understanding) by the audio-transformation-visualization GUI (made by phrasenmaeher), where you can upload your own input wav file</p>"},{"location":"#composition-classes","title":"Composition classes","text":""},{"location":"#compose","title":"<code>Compose</code>","text":"<p>Compose applies the given sequence of transforms when called, optionally shuffling the sequence for every call.</p>"},{"location":"#oneof","title":"<code>OneOf</code>","text":"<p>OneOf randomly picks one of the given transforms when called, and applies that transform. </p> <p>An optional <code>weights</code> list of floats may be given to guide the probability of each transform for being chosen. If not specified, a transform is chosen uniformly at random.</p> <p>Code example:</p> <pre><code>from audiomentations import OneOf, PitchShift\n\npitch_shift = OneOf(\n    transforms=[\n        PitchShift(method=\"librosa_phase_vocoder\"),\n        PitchShift(method=\"signalsmith_stretch\"),\n    ],\n    p=1.0,\n    weights=[0.1, 0.9],\n)\n</code></pre>"},{"location":"#someof","title":"<code>SomeOf</code>","text":"<p>SomeOf randomly picks several of the given transforms when called, and applies those transforms.</p>"},{"location":"#known-limitations","title":"Known limitations","text":"<ul> <li>A few transforms do not support multichannel audio yet. See Multichannel audio</li> <li>Expects the input dtype to be float32, and have values between -1 and 1.</li> <li>The code runs on CPU, not GPU. For a GPU-compatible version, check out pytorch-audiomentations</li> <li>Multiprocessing probably works but is not officially supported yet</li> </ul> <p>Contributions are welcome!</p>"},{"location":"#multichannel-audio","title":"Multichannel audio","text":"<p>As of v0.22.0, all transforms except <code>AddBackgroundNoise</code> and <code>AddShortNoises</code> support not only mono audio (1-dimensional numpy arrays), but also stereo audio, i.e. 2D arrays with shape like <code>(num_channels, num_samples)</code>. See also the guide on multichannel audio array shapes.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>Thanks to Nomono for backing audiomentations.</p> <p>Thanks to all contributors who help improving audiomentations.</p>"},{"location":"alternatives/","title":"Alternatives","text":"<p>Audiomentations isn't the only python library that can do various types of audio data augmentation/degradation! Here's an overview:</p> Name Github stars License Last commit GPU support? audio-degradation-toolbox audio_degrader audiomentations audiotools auglib AugLy fast-audiomentations kapre muda nlpaug pedalboard pydiogment python-audio-effects SpecAugment spec_augment teal torch-audiomentations torchaudio-augmentations torchfx WavAugment"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#0431-2025-09-13","title":"[0.43.1] - 2025-09-13","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Fix a bug introduced in 0.43.0 where the noise added by <code>AddBackgroundNoise</code> had wrong offset if the noise was longer than the given signal.</li> </ul>"},{"location":"changelog/#0430-2025-09-09","title":"0.43.0 - 2025-09-09","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Make <code>LoudnessNormalization</code> 400% faster by switching from pyloudnorm to the new and faster alternative loudness </li> <li>Improve <code>AddBackgroundNoise</code> performance: Only load/decode the part of the noise file that is needed, instead of the entire file.</li> <li>Bump min Python version to 3.10</li> <li>Switch to a more modern type hint style</li> </ul>"},{"location":"changelog/#deprecated","title":"Deprecated","text":"<ul> <li>Deprecate <code>\"pydub\"</code> backend in <code>Mp3Compression</code>, because pydub isn't maintained anymore, and depends on audioop, which got removed in Python 3.13. The recommended alternative is <code>\"fast-mp3-augment\"</code></li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li>Remove upper Python version limit to avoid hindering early adopters</li> <li>Remove LRU cache in <code>AddBackgroundNoise</code></li> </ul>"},{"location":"changelog/#0420-2025-07-04","title":"0.42.0 - 2025-07-04","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Add support for Python 3.13</li> <li>Add support for librosa 0.11.0</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Make <code>Mp3Compression</code> 25-300% faster (depending on hardware, audio properties like duration and number of channels and various params, like bitrate) with the new <code>backend=\"fast-mp3-augment\"</code> (now default). The extra dependency for this is fast-mp3-augment , which pulls a few useful tricks for faster execution. </li> <li>Make <code>Limiter</code> 30% faster and easier to install (extra dependency is now numpy-audio-limiter  instead of cylimiter ). The <code>Limiter</code> behavior has not changed, although there are minor numerical differences.</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Handle non-contiguous audio ndarray input to <code>PitchShift</code> and <code>TimeStretch</code> properly</li> </ul>"},{"location":"changelog/#0410-2025-05-05","title":"0.41.0 - 2025-05-05","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Add support for NumPy 2.x</li> <li>Add <code>weights</code> parameter to <code>OneOf</code>. This lets you guide the probability of each transform being chosen.</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>Improve type hints</li> </ul>"},{"location":"changelog/#the-timemask-transform-has-been-changed-significantly","title":"The <code>TimeMask</code> transform has been changed significantly:","text":"<ul> <li>Breaking change: Remove <code>fade</code> parameter. <code>fade_duration=0.0</code> now denotes disabled fading.</li> <li>Enable fading by default</li> <li>Apply a smooth fade curve instead of a linear one</li> <li>Add <code>mask_location</code> parameter</li> <li>Change the default value of <code>min_band_part</code> from 0.0 to 0.01</li> <li>Change the default value of <code>max_band_part</code> from 0.5 to 0.2</li> <li>~50% faster</li> </ul> <p>The following examples show how you can adapt your code when upgrading from &lt;=v0.40.0 to &gt;=v0.41.0:</p> &lt;= 0.40.0 &gt;= 0.41.0 <code>TimeMask(min_band_part=0.1, max_band_part=0.15, fade=True)</code> <code>TimeMask(min_band_part=0.1, max_band_part=0.15, fade_duration=0.01)</code> <code>TimeMask()</code> <code>TimeMask(min_band_part=0.0, max_band_part=0.5, fade_duration=0.0)</code>"},{"location":"changelog/#removed_1","title":"Removed","text":"<ul> <li><code>SpecCompose</code>, <code>SpecChannelShuffle</code> and <code>SpecFrequencyMask</code> have been removed. You can read more about this here: #391</li> </ul>"},{"location":"changelog/#0400-2025-03-20","title":"0.40.0 - 2025-03-20","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Add support for scipy&gt;=1.13</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>Lay the groundwork for NumPy 2.x support (version constraint update coming in the next release)</li> <li>Speed up <code>LoudnessNormalization</code> by ~20%</li> <li>Improve test coverage and documentation</li> <li>Bump min <code>python-stretch</code> version and remove the limitation on the number of channels in <code>PitchShift</code></li> <li>Bump min numpy version to 1.22</li> <li>Bump min pyroomacoustics version to 0.7.4</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":"<ul> <li>Fix a bug where <code>TimeMask</code> could raise an exception if the fade length became 0</li> <li>Disallow <code>min_cutoff_freq</code> &lt;= 0 in <code>HighPassFilter</code></li> <li>Make <code>AdjustDuration</code> picklable (useful for multiprocessing)</li> </ul>"},{"location":"changelog/#removed_2","title":"Removed","text":"<ul> <li>Remove support for Python 3.8</li> </ul>"},{"location":"changelog/#0390-2025-02-12","title":"0.39.0 - 2025-02-12","text":""},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>Place an upper distance limit of 2500 meters in <code>AirAbsorption</code> in order to avoid numerical issues</li> <li>Expand the allowed shift range in <code>PitchShift</code> from [-12, 12] to [-24, 24]</li> <li>Switch to a higher quality method, <code>\"signalsmith_stretch\"</code>, in <code>PitchShift</code> and <code>TimeStretch</code>. It sounds significantly   better (e.g. less smearing) and is 50-100% faster than <code>\"librosa_phase_vocoder\"</code></li> </ul> <p>If you want to keep using the old method, <code>\"librosa_phase_vocoder\"</code>, it can be done like this:</p> <pre><code>PitchShift(method=\"librosa_phase_vocoder\")\nTimeStretch(method=\"librosa_phase_vocoder\")\n</code></pre>"},{"location":"changelog/#fixed_3","title":"Fixed","text":"<ul> <li>Fix a bug where <code>AddShortNoises(include_silence_in_noise_rms_estimation=False)</code> sometimes raised a <code>ValueError</code> due to   digital silence in a portion of a short noise. This bug was introduced in v0.36.1.</li> </ul>"},{"location":"changelog/#0380-2024-12-06","title":"0.38.0 - 2024-12-06","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Add/improve parameter validation in <code>AddGaussianSNR</code>, <code>GainTransition</code>, <code>LoudnessNormalization</code> and <code>AddShortNoises</code></li> <li>Add/update type hints for consistency</li> <li>Add human-readable string representation of audiomentations class instances</li> </ul>"},{"location":"changelog/#changed_5","title":"Changed","text":"<ul> <li>Improve documentation with respect to consistency, clarity and grammar</li> <li>Adjust Python version compatibility range, so all patches of Python 3.12 are supported</li> </ul>"},{"location":"changelog/#removed_3","title":"Removed","text":"<ul> <li>Remove deprecated *_in_db args   in Gain, AddBackgroundNoise, AddGaussianSNR, GainTransition, LoudnessNormalization   and AddShortNoises. Those args were deprecated since v0.31.0, and now they   are gone. For details, check the documentation page of each transform.</li> </ul> <p>For example:</p> Old (deprecated since v0.31.0) New <code>Gain(min_gain_in_db=-12.0)</code> <code>Gain(min_gain_db=-12.0)</code>"},{"location":"changelog/#fixed_4","title":"Fixed","text":"<ul> <li>Fix a bug where <code>AirAbsorption</code> often chose the wrong humidity bucket</li> <li>Fix wrong logic in validation check of relation between <code>crossfade_duration</code> and <code>min_part_duration</code> in <code>RepeatPart</code></li> <li>Fix default value of <code>max_absolute_rms_db</code> in <code>AddBackgroundNoises</code>. It was incorrectly set to -45.0, but is now   -15.0. This bug was introduced in v0.31.0.</li> <li>Fix various errors in the documentation of <code>AddShortNoises</code> and <code>AirAbsorption</code></li> <li>Fix a bug where <code>AddShortNoises</code> sometimes raised a <code>ValueError</code> because of an empty array. This bug was introduced in   v0.36.1.</li> </ul>"},{"location":"changelog/#0370-2024-09-03","title":"0.37.0 - 2024-09-03","text":""},{"location":"changelog/#changed_6","title":"Changed","text":"<ul> <li>Leverage the SIMD-accelerated numpy-minmax package for speed   improvements. These transforms are faster now: <code>Limiter</code>, <code>Mp3Compression</code> and <code>Normalize</code>. Unfortunately, this change   removes support for macOS running on Intel. Intel Mac users have the following options: A) use audiomentations 0.36.1,   B) Create a fork of audiomentations, C) submit a patch to numpy-minmax, D) run Linux or Windows.</li> <li>Limit numpy dependency to &gt;=1.21,&lt;2 for now, since numpy v2 is not officially supported yet.</li> </ul>"},{"location":"changelog/#0361-2024-08-20","title":"0.36.1 - 2024-08-20","text":""},{"location":"changelog/#changed_7","title":"Changed","text":"<ul> <li>Leverage the SIMD-accelerated numpy-rms package for significant speed   improvements. These transforms are faster now: <code>AddBackgroundNoise</code>, <code>AddColorNoise</code>, <code>AddGaussianSNR</code>,   <code>AddShortNoises</code>, <code>Mp3Compression</code> and <code>TanhDistortion</code>. Unfortunately, this change removes support for Windows   running on ARM.</li> </ul>"},{"location":"changelog/#0360-2024-06-10","title":"0.36.0 - 2024-06-10","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Add support for multichannel impulse responses in <code>ApplyImpulseResponse</code></li> </ul>"},{"location":"changelog/#changed_8","title":"Changed","text":"<ul> <li> <code>Limiter</code> no longer introduces delay. This is a backwards-incompatible change.</li> <li>Make <code>RoomSimulator</code> faster by avoiding unneeded calculations when the transform is not going to be applied (p&lt;1)</li> <li>Limit scipy dependency to &lt;1.13 because 1.13 is not compatible for now.</li> </ul>"},{"location":"changelog/#0350-2024-03-15","title":"0.35.0 - 2024-03-15","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Add new transforms: <code>AddColorNoise</code>, <code>Aliasing</code> and <code>BitCrush</code></li> </ul>"},{"location":"changelog/#0341-2023-11-24","title":"0.34.1 - 2023-11-24","text":""},{"location":"changelog/#changed_9","title":"Changed","text":"<ul> <li>Bump min numpy version from 1.18 to 1.21</li> <li>Use numpy.typing in type hints</li> <li>Optimize max abs calculations in terms of memory and speed. This makes <code>Normalize</code>, <code>Mp3Compression</code> and <code>Limiter</code>   slightly faster.</li> </ul>"},{"location":"changelog/#0330-2023-08-30","title":"0.33.0 - 2023-08-30","text":""},{"location":"changelog/#changed_10","title":"Changed","text":"<ul> <li>Bump min numpy version from 1.16 to 1.18</li> <li>Bump min scipy version from 1.3 to 1.4</li> <li>Bump min python version from 3.7 to 3.8, because 3.7 is beyond end-of-life already</li> <li>Change some <code>AssertionError</code> exceptions to <code>ValueError</code></li> </ul>"},{"location":"changelog/#the-shift-transform-has-been-changed","title":"The <code>Shift</code> transform has been changed:","text":"<ul> <li>Removed <code>fade</code> parameter. <code>fade_duration=0.0</code> now denotes disabled fading.</li> <li>Rename <code>min_fraction</code> to <code>min_shift</code> and <code>max_fraction</code> to <code>max_shift</code></li> <li>Add <code>shift_unit</code> parameter</li> <li>Fading is enabled by default</li> <li>Smoother fade curve</li> </ul> <p>These are breaking changes. The following examples show how you can adapt your code when upgrading from &lt;=v0.32.0 to &gt;=v0.33.0:</p> &lt;= 0.32.0 &gt;= 0.33.0 <code>Shift(min_fraction=-0.5, max_fraction=0.5, fade=True, fade_duration=0.01)</code> <code>Shift(min_shift=-0.5, max_shift=0.5, shift_unit=\"fraction\", fade_duration=0.01)</code> <code>Shift()</code> <code>Shift(fade_duration=0.0)</code>"},{"location":"changelog/#fixed_5","title":"Fixed","text":"<ul> <li>Correct some wrong type hints</li> </ul>"},{"location":"changelog/#0320-2023-08-15","title":"0.32.0 - 2023-08-15","text":""},{"location":"changelog/#added_6","title":"Added","text":"<ul> <li>Add new <code>RepeatPart</code> transform</li> </ul>"},{"location":"changelog/#changed_11","title":"Changed","text":"<ul> <li>Bump min version of numpy dependency from 1.13 to 1.16</li> <li>If a transform is in \"frozen parameters\" mode, but has no parameters yet, the transform will randomize/set parameters   when it gets called for the first time</li> <li>Increase the threshold for raising <code>WrongMultichannelAudioShape</code>. This allows some rare use cases where the number of   channels slightly exceeds the number of samples.</li> </ul>"},{"location":"changelog/#fixed_6","title":"Fixed","text":"<ul> <li>Fix some type hints that were <code>np.array</code> instead of <code>np.ndarray</code></li> </ul>"},{"location":"changelog/#0310-2023-06-21","title":"0.31.0 - 2023-06-21","text":""},{"location":"changelog/#changed_12","title":"Changed","text":"<ul> <li>Raise exception instead of warning when the given multichannel ndarray has wrong shape</li> <li>Add support for the latest librosa 0.10 version</li> <li>Switch to a faster default resampler internally in <code>PitchShift</code>, leading to much faster execution. This requires   <code>soxr</code>.</li> <li>Bump min <code>scipy</code> requirement from 1.0 to 1.3</li> <li>Rename \"_in_db\" to \"_db\" in args and parameters. Passing args with the old names still works, but is deprecated and   will stop working in a future version.</li> </ul>"},{"location":"changelog/#0300-2023-05-02","title":"0.30.0 - 2023-05-02","text":""},{"location":"changelog/#added_7","title":"Added","text":"<ul> <li>Add new <code>AdjustDuration</code> transform</li> </ul>"},{"location":"changelog/#fixed_7","title":"Fixed","text":"<ul> <li>Fix a bug where too loud inputs got wrap distortion when running them through <code>Mp3Compression</code></li> </ul>"},{"location":"changelog/#0290-2023-03-15","title":"0.29.0 - 2023-03-15","text":""},{"location":"changelog/#added_8","title":"Added","text":"<ul> <li>Add <code>apply_to</code> parameter that can be set to <code>\"only_too_loud_sounds\"</code> in <code>Normalize</code></li> </ul>"},{"location":"changelog/#changed_13","title":"Changed","text":"<ul> <li>Change default value of <code>noise_rms</code> from <code>\"relative\"</code> to <code>\"relative_to_whole_input\"</code> in <code>AddShortNoises</code></li> <li>Change default values of <code>min_snr_in_db</code> (from <code>0.0</code> to <code>-6.0</code>), <code>max_snr_in_db</code> (from <code>24.0</code> to <code>18.0</code>),   <code>min_time_between_sounds</code> (from <code>4.0</code> to <code>2.0</code>) and <code>max_time_between_sounds</code> (from <code>16.0</code> to <code>8.0</code>) in   <code>AddShortNoises</code></li> </ul>"},{"location":"changelog/#fixed_8","title":"Fixed","text":"<ul> <li>Fix a bug where <code>Limiter</code> raised an exception when it got digital silence as input</li> </ul>"},{"location":"changelog/#0280-2023-01-12","title":"0.28.0 - 2023-01-12","text":""},{"location":"changelog/#added_9","title":"Added","text":"<ul> <li>Add/improve type hints</li> <li>Add/improve documentation</li> </ul>"},{"location":"changelog/#fixed_9","title":"Fixed","text":"<ul> <li>Fix a bug in <code>RoomSimulator</code> where the value of <code>max_order</code> was not respected</li> </ul>"},{"location":"changelog/#removed_4","title":"Removed","text":"<ul> <li>Remove <code>FrequencyMask</code> that had been deprecated since version 0.22.0. <code>BandStopFilter</code> is a good alternative.</li> </ul>"},{"location":"changelog/#0270-2022-09-13","title":"0.27.0 - 2022-09-13","text":""},{"location":"changelog/#changed_14","title":"Changed","text":"<ul> <li>Speed up <code>Limiter</code> by ~8x</li> <li>Fix/improve some docstrings and type hints</li> <li>Change default values in <code>Trim</code> and <code>ApplyImpulseResponse</code> according to the warnings that were added in v0.23.0</li> <li>Emit a FutureWarning when <code>noise_rms</code> in <code>AddShortNoises</code> is not specified - the   default value will change from \"relative\" to \"relative_to_whole_input\" in a future version.</li> </ul>"},{"location":"changelog/#0260-2022-08-19","title":"0.26.0 - 2022-08-19","text":""},{"location":"changelog/#added_10","title":"Added","text":"<ul> <li>Add new transform <code>Lambda</code>. Thanks to Thanatoz-1.</li> <li>Add new transform <code>Limiter</code>. Thanks to pzelasko.</li> </ul>"},{"location":"changelog/#fixed_10","title":"Fixed","text":"<ul> <li>Fix incorrect type hints in <code>RoomSimulator</code></li> <li>Make <code>Shift</code> robust to different sample rate inputs when parameters are frozen</li> </ul>"},{"location":"changelog/#0251-2022-06-15","title":"0.25.1 - 2022-06-15","text":""},{"location":"changelog/#fixed_11","title":"Fixed","text":"<ul> <li>Fix a bug where <code>RoomSimulator</code> would treat an x value as if it was y, and vice versa</li> </ul>"},{"location":"changelog/#0250-2022-05-30","title":"0.25.0 - 2022-05-30","text":""},{"location":"changelog/#added_11","title":"Added","text":"<ul> <li>Add <code>AirAbsorption</code> transform</li> <li>Add mp4 to the list of recognized audio filename extensions</li> </ul>"},{"location":"changelog/#changed_15","title":"Changed","text":"<ul> <li>Guard against invalid params in <code>TimeMask</code></li> <li>Emit <code>FutureWarning</code> instead of <code>UserWarning</code> in <code>Trim</code> and <code>ApplyImpulseResponse</code></li> <li>Allow specifying a file path, a folder path, a list of files or a list of folders to   <code>ApplyImpulseResponse</code>, <code>AddBackgroundNoise</code> and <code>AddShortNoises</code>. Previously only a path to a folder was allowed.</li> </ul>"},{"location":"changelog/#fixed_12","title":"Fixed","text":"<ul> <li>Fix a bug with <code>noise_transform</code> in <code>AddBackgroundNoise</code> where some   SNR calculations were done before the <code>noise_transform</code> was applied. This has sometimes   led to incorrect SNR in the output. This changes the behavior of   <code>AddBackgroundNoise</code> (when noise_transform is used).</li> </ul>"},{"location":"changelog/#removed_5","title":"Removed","text":"<ul> <li>Remove support for Python 3.6, as it is past its end of life already. RIP.</li> </ul>"},{"location":"changelog/#0240-2022-03-18","title":"0.24.0 - 2022-03-18","text":""},{"location":"changelog/#added_12","title":"Added","text":"<ul> <li>Add <code>SevenBandParametricEQ</code> transform</li> <li>Add optional <code>noise_transform</code> in <code>AddShortNoises</code></li> <li>Add .aac and .aif to the list of recognized audio filename endings</li> </ul>"},{"location":"changelog/#changed_16","title":"Changed","text":"<ul> <li>Show warning if <code>top_db</code> and/or <code>p</code> in <code>Trim</code> are not specified because their default   values will change in a future version</li> </ul>"},{"location":"changelog/#fixed_13","title":"Fixed","text":"<ul> <li>Fix filter instability bug related to center freq above Nyquist freq in <code>LowShelfFilter</code> and <code>HighShelfFilter</code></li> </ul>"},{"location":"changelog/#0230-2022-03-07","title":"0.23.0 - 2022-03-07","text":""},{"location":"changelog/#added_13","title":"Added","text":"<ul> <li>Add <code>Padding</code> transform</li> <li>Add <code>RoomSimulator</code> transform for simulating shoebox rooms using <code>pyroomacoustics</code></li> <li>Add parameter <code>signal_gain_in_db_during_noise</code> in <code>AddShortNoises</code></li> </ul>"},{"location":"changelog/#changed_17","title":"Changed","text":"<ul> <li>Not specifying a value for <code>leave_length_unchanged</code> in <code>AddImpulseResponse</code> now emits   a warning, as the default value will change from <code>False</code> to <code>True</code> in a future version.</li> </ul>"},{"location":"changelog/#removed_6","title":"Removed","text":"<ul> <li>Remove the deprecated <code>AddImpulseResponse</code> alias. Use <code>ApplyImpulseResponse</code> instead.</li> <li>Remove support for the legacy parameters <code>min_SNR</code> and <code>max_SNR</code> in <code>AddGaussianSNR</code></li> <li>Remove useless default path value in <code>AddBackgroundNoise</code>, <code>AddShortNoises</code> and <code>ApplyImpulseResponse</code></li> </ul>"},{"location":"changelog/#0220-2022-02-18","title":"0.22.0 - 2022-02-18","text":""},{"location":"changelog/#added_14","title":"Added","text":"<ul> <li>Implement <code>GainTransition</code></li> <li>Add support for librosa 0.9</li> <li>Add support for stereo audio in <code>Mp3Compression</code>, <code>Resample</code> and <code>Trim</code></li> <li>Add <code>\"relative_to_whole_input\"</code> option for <code>noise_rms</code> parameter in <code>AddShortNoises</code></li> <li>Add optional <code>noise_transform</code> in <code>AddBackgroundNoise</code></li> </ul>"},{"location":"changelog/#changed_18","title":"Changed","text":"<ul> <li>Improve speed of <code>PitchShift</code> by 6-18% when the input audio is stereo</li> </ul>"},{"location":"changelog/#deprecated_1","title":"Deprecated","text":"<ul> <li>Deprecate <code>FrequencyMask</code> in favor of <code>BandStopFilter</code></li> </ul>"},{"location":"changelog/#removed_7","title":"Removed","text":"<ul> <li>Remove support for librosa&lt;=0.7.2</li> </ul>"},{"location":"changelog/#0210-2022-02-10","title":"0.21.0 - 2022-02-10","text":""},{"location":"changelog/#added_15","title":"Added","text":"<ul> <li>Add support for multichannel audio in <code>ApplyImpulseResponse</code>, <code>BandPassFilter</code>, <code>HighPassFilter</code> and <code>LowPassFilter</code></li> <li>Add <code>BandStopFilter</code> (similar to FrequencyMask, but with overhauled defaults and parameter randomization behavior),   <code>PeakingFilter</code>, <code>LowShelfFilter</code> and <code>HighShelfFilter</code></li> <li>Add parameter <code>add_all_noises_with_same_level</code> in <code>AddShortNoises</code></li> </ul>"},{"location":"changelog/#changed_19","title":"Changed","text":"<ul> <li>Change <code>BandPassFilter</code>, <code>LowPassFilter</code>, <code>HighPassFilter</code>, to use scipy's butterworth   filters instead of pydub. Now they have parametrized roll-off. Filters are now steeper   than before by default - set <code>min_rolloff=6, max_rolloff=6</code> to get the old behavior.   They also support zero-phase filtering now. And they're at least ~25x times faster than before!</li> </ul>"},{"location":"changelog/#removed_8","title":"Removed","text":"<ul> <li>Remove optional <code>wavio</code> dependency for audio loading</li> </ul>"},{"location":"changelog/#0200-2021-11-18","title":"0.20.0 - 2021-11-18","text":""},{"location":"changelog/#added_16","title":"Added","text":"<ul> <li>Implement <code>OneOf</code> and <code>SomeOf</code> for applying one of or some of many transforms. Transforms are randomly   chosen every call. Inspired by augly. Thanks to Cangonin and iver56.</li> <li>Add a new argument <code>apply_to_children</code> (bool) in <code>randomize_parameters</code>,   <code>freeze_parameters</code> and <code>unfreeze_parameters</code> in <code>Compose</code> and <code>SpecCompose</code>.</li> </ul>"},{"location":"changelog/#changed_20","title":"Changed","text":"<ul> <li>Insert three new parameters in <code>AddBackgroundNoise</code>: <code>noise_rms</code> (defaults to \"relative\", which is   the old behavior), <code>min_absolute_rms_in_db</code> and <code>max_absolute_rms_in_db</code>. This may be a breaking   change if you used <code>AddBackgroundNoise</code> with positional arguments in earlier versions of audiomentations!   Please use keyword arguments to be on the safe side - it should be backwards compatible then.</li> </ul>"},{"location":"changelog/#fixed_14","title":"Fixed","text":"<ul> <li>Remove global <code>pydub</code> import which was accidentally introduced in v0.18.0. <code>pydub</code> is   considered an optional dependency and is imported only on demand now.</li> </ul>"},{"location":"changelog/#0190-2021-10-18","title":"0.19.0 - 2021-10-18","text":""},{"location":"changelog/#added_17","title":"Added","text":"<ul> <li>Implement <code>TanhDistortion</code>. Thanks to atamazian and iver56.</li> <li>Add a <code>noise_rms</code> parameter to <code>AddShortNoises</code>. It defaults to <code>relative</code>, which   is the old behavior. <code>absolute</code> allows for adding loud noises to parts that are   relatively silent in the input.</li> </ul>"},{"location":"changelog/#0180-2021-08-05","title":"0.18.0 - 2021-08-05","text":""},{"location":"changelog/#added_18","title":"Added","text":"<ul> <li>Implement <code>BandPassFilter</code>, <code>HighPassFilter</code>, <code>LowPassFilter</code> and <code>Reverse</code>. Thanks to atamazian.</li> </ul>"},{"location":"changelog/#0170-2021-06-25","title":"0.17.0 - 2021-06-25","text":""},{"location":"changelog/#added_19","title":"Added","text":"<ul> <li>Add a <code>fade</code> option in <code>Shift</code> for eliminating unwanted clicks</li> <li>Add support for 32-bit int wav loading with scipy&gt;=1.6</li> <li>Add support for float64 wav files. However, the use of this format is discouraged,   since float32 is more than enough for audio in most cases.</li> <li>Implement <code>Clip</code>. Thanks to atamazian.</li> <li>Add some parameter sanity checks in <code>AddGaussianNoise</code></li> <li>Officially support librosa 0.8.1</li> </ul>"},{"location":"changelog/#changed_21","title":"Changed","text":"<ul> <li>Rename <code>AddImpulseResponse</code> to <code>ApplyImpulseResponse</code>. The former will still work for   now, but give a warning.</li> <li>When looking for audio files in <code>AddImpulseResponse</code>, <code>AddBackgroundNoise</code>   and <code>AddShortNoises</code>, follow symlinks by default.</li> <li>When using the new parameters <code>min_snr_in_db</code> and <code>max_snr_in_db</code> in <code>AddGaussianSNR</code>,   SNRs will be picked uniformly in the Decibel scale instead of in the linear amplitude   ratio scale. The new behavior aligns more with human hearing, which is not linear.</li> </ul>"},{"location":"changelog/#fixed_15","title":"Fixed","text":"<ul> <li>Avoid division by zero in <code>AddImpulseResponse</code> when input is digital silence (all zeros)</li> <li>Fix inverse SNR characteristics in <code>AddGaussianSNR</code>. It will continue working as before   unless you switch to the new parameters <code>min_snr_in_db</code> and <code>max_snr_in_db</code>. If you   use the old parameters, you'll get a warning.</li> </ul>"},{"location":"changelog/#0160-2021-02-11","title":"0.16.0 - 2021-02-11","text":""},{"location":"changelog/#added_20","title":"Added","text":"<ul> <li>Implement <code>SpecCompose</code> for applying a pipeline of spectrogram transforms. Thanks to omerferhatt.</li> </ul>"},{"location":"changelog/#fixed_16","title":"Fixed","text":"<ul> <li>Fix a bug in <code>SpecChannelShuffle</code> where it did not support more than 3 audio channels. Thanks to omerferhatt.</li> <li>Limit scipy version range to &gt;=1.0,&lt;1.6 to avoid issues with loading 24-bit wav files.   Support for scipy&gt;=1.6 will be added later.</li> </ul>"},{"location":"changelog/#0150-2020-12-10","title":"0.15.0 - 2020-12-10","text":""},{"location":"changelog/#added_21","title":"Added","text":"<ul> <li>Add an option <code>leave_length_unchanged</code> to <code>AddImpulseResponse</code></li> </ul>"},{"location":"changelog/#fixed_17","title":"Fixed","text":"<ul> <li>Fix picklability of instances of <code>AddImpulseResponse</code>, <code>AddBackgroundNoise</code>   and <code>AddShortNoises</code></li> </ul>"},{"location":"changelog/#0140-2020-12-06","title":"0.14.0 - 2020-12-06","text":""},{"location":"changelog/#added_22","title":"Added","text":"<ul> <li>Implement <code>LoudnessNormalization</code></li> <li>Implement <code>randomize_parameters</code> in <code>Compose</code>. Thanks to SolomidHero.</li> <li>Add multichannel support to <code>AddGaussianNoise</code>, <code>AddGaussianSNR</code>, <code>ClippingDistortion</code>,   <code>FrequencyMask</code>, <code>PitchShift</code>, <code>Shift</code>, <code>TimeMask</code> and <code>TimeStretch</code></li> </ul>"},{"location":"changelog/#0130-2020-11-10","title":"0.13.0 - 2020-11-10","text":""},{"location":"changelog/#added_23","title":"Added","text":"<ul> <li>Lay the foundation for spectrogram transforms. Implement <code>SpecChannelShuffle</code> and   <code>SpecFrequencyMask</code>.</li> <li>Configurable LRU cache for transforms that use external sound files. Thanks to alumae.</li> <li>Officially add multichannel support to <code>Normalize</code></li> </ul>"},{"location":"changelog/#changed_22","title":"Changed","text":"<ul> <li>Show a warning if a waveform had to be resampled after loading it. This is because resampling   is slow. Ideally, files on disk should already have the desired sample rate.</li> </ul>"},{"location":"changelog/#fixed_18","title":"Fixed","text":"<ul> <li>Correctly find audio files with upper case filename extensions.</li> <li>Fix a bug where AddBackgroundNoise crashed when trying to add digital silence to an input. Thanks to juheeuu.</li> </ul>"},{"location":"changelog/#0121-2020-09-28","title":"0.12.1 - 2020-09-28","text":""},{"location":"changelog/#changed_23","title":"Changed","text":"<ul> <li>Speed up <code>AddBackgroundNoise</code>, <code>AddShortNoises</code> and <code>AddImpulseResponse</code> by loading wav files with scipy or wavio   instead of librosa.</li> </ul>"},{"location":"changelog/#0120-2020-09-23","title":"0.12.0 - 2020-09-23","text":""},{"location":"changelog/#added_24","title":"Added","text":"<ul> <li>Implement <code>Mp3Compression</code></li> <li>Officially support multichannel audio in <code>Gain</code> and <code>PolarityInversion</code></li> <li>Add m4a and opus to the list of recognized audio filename extensions</li> </ul>"},{"location":"changelog/#changed_24","title":"Changed","text":"<ul> <li>Expand range of supported <code>librosa</code> versions</li> </ul>"},{"location":"changelog/#removed_9","title":"Removed","text":"<ul> <li>Python &lt;= 3.5 is no longer officially supported,   since Python 3.5 has reached end-of-life</li> <li>Breaking change: Internal util functions are no longer exposed directly. If you were doing   e.g. <code>from audiomentations import calculate_rms</code>, now you have to do   <code>from audiomentations.core.utils import calculate_rms</code></li> </ul>"},{"location":"changelog/#0110-2020-08-27","title":"0.11.0 - 2020-08-27","text":""},{"location":"changelog/#added_25","title":"Added","text":"<ul> <li>Implement <code>Gain</code> and <code>PolarityInversion</code>. Thanks to Spijkervet for the inspiration.</li> </ul>"},{"location":"changelog/#0101-2020-07-27","title":"0.10.1 - 2020-07-27","text":""},{"location":"changelog/#changed_25","title":"Changed","text":"<ul> <li>Improve the performance of <code>AddBackgroundNoise</code> and <code>AddShortNoises</code> by optimizing the implementation of   <code>calculate_rms</code>.</li> </ul>"},{"location":"changelog/#fixed_19","title":"Fixed","text":"<ul> <li>Improve compatibility of output files written by the demo script. Thanks to xwJohn.</li> <li>Fix division by zero bug in <code>Normalize</code>. Thanks to ZFTurbo.</li> </ul>"},{"location":"changelog/#0100-2020-05-05","title":"0.10.0 - 2020-05-05","text":""},{"location":"changelog/#added_26","title":"Added","text":"<ul> <li><code>AddImpulseResponse</code>, <code>AddBackgroundNoise</code> and <code>AddShortNoises</code> now support aiff files in addition to flac, mp3, ogg   and wav</li> </ul>"},{"location":"changelog/#changed_26","title":"Changed","text":"<ul> <li>Breaking change: <code>AddImpulseResponse</code>, <code>AddBackgroundNoise</code> and <code>AddShortNoises</code> now include subfolders when searching   for files. This is useful when your sound files are organized in subfolders.</li> </ul>"},{"location":"changelog/#fixed_20","title":"Fixed","text":"<ul> <li>Fix filter instability bug in <code>FrequencyMask</code>. Thanks to kvilouras.</li> </ul>"},{"location":"changelog/#090-2020-02-20","title":"0.9.0 - 2020-02-20","text":""},{"location":"changelog/#added_27","title":"Added","text":"<ul> <li>Remember randomized/chosen effect parameters. This allows for freezing the parameters and applying the same effect to   multiple sounds. Use transform.freeze_parameters() and transform.unfreeze_parameters() for this.</li> <li>Implement transform.serialize_parameters(). Useful for when you want to store metadata on how a sound was perturbed.</li> <li>Add a rollover parameter to <code>Shift</code>. This allows for introducing silence instead of a wrapped part of the sound.</li> <li>Add support for flac in <code>AddImpulseResponse</code></li> <li>Implement <code>AddBackgroundNoise</code> transform. Useful for when you want to add background noise to all of your sound. You   need to give it a folder of background noises to choose from.</li> <li>Implement <code>AddShortNoises</code>. Useful for when you want to add (bursts of) short noise sounds to your input audio.</li> </ul>"},{"location":"changelog/#changed_27","title":"Changed","text":"<ul> <li>Disregard non-audio files when looking for impulse response files</li> <li>Switch to a faster convolve implementation. This makes <code>AddImpulseResponse</code> significantly faster.</li> <li>Expand supported range of librosa versions</li> </ul>"},{"location":"changelog/#fixed_21","title":"Fixed","text":"<ul> <li>Fix a bug in <code>ClippingDistortion</code> where the min_percentile_threshold was not respected as expected.</li> <li>Improve handling of empty input</li> </ul>"},{"location":"changelog/#080-2020-01-28","title":"0.8.0 - 2020-01-28","text":""},{"location":"changelog/#added_28","title":"Added","text":"<ul> <li>Add shuffle parameter in <code>Composer</code></li> <li>Add <code>Resample</code> transformation</li> <li>Add <code>ClippingDistortion</code> transformation</li> <li>Add <code>fade</code> parameter to <code>TimeMask</code></li> </ul> <p>Thanks to askskro</p>"},{"location":"changelog/#070-2020-01-14","title":"0.7.0 - 2020-01-14","text":""},{"location":"changelog/#added_29","title":"Added","text":"<ul> <li><code>AddGaussianSNR</code></li> <li><code>AddImpulseResponse</code></li> <li><code>FrequencyMask</code></li> <li><code>TimeMask</code></li> <li><code>Trim</code></li> </ul> <p>Thanks to karpnv</p>"},{"location":"changelog/#060-2019-05-27","title":"0.6.0 - 2019-05-27","text":""},{"location":"changelog/#added_30","title":"Added","text":"<ul> <li>Implement peak normalization</li> </ul>"},{"location":"changelog/#050-2019-02-23","title":"0.5.0 - 2019-02-23","text":""},{"location":"changelog/#added_31","title":"Added","text":"<ul> <li>Implement <code>Shift</code> transform</li> </ul>"},{"location":"changelog/#changed_28","title":"Changed","text":"<ul> <li>Ensure p is within bounds</li> </ul>"},{"location":"changelog/#040-2019-02-19","title":"0.4.0 - 2019-02-19","text":""},{"location":"changelog/#added_32","title":"Added","text":"<ul> <li>Implement <code>PitchShift</code> transform</li> </ul>"},{"location":"changelog/#fixed_22","title":"Fixed","text":"<ul> <li>Fix output dtype of <code>AddGaussianNoise</code></li> </ul>"},{"location":"changelog/#030-2019-02-19","title":"0.3.0 - 2019-02-19","text":""},{"location":"changelog/#added_33","title":"Added","text":"<ul> <li>Implement <code>leave_length_unchanged</code> in <code>TimeStretch</code></li> </ul>"},{"location":"changelog/#020-2019-02-18","title":"0.2.0 - 2019-02-18","text":""},{"location":"changelog/#added_34","title":"Added","text":"<ul> <li>Add <code>TimeStretch</code> transform</li> <li>Parametrize <code>AddGaussianNoise</code></li> </ul>"},{"location":"changelog/#010-2019-02-15","title":"0.1.0 - 2019-02-15","text":""},{"location":"changelog/#added_35","title":"Added","text":"<ul> <li>Initial release. Includes only one transform: <code>AddGaussianNoise</code></li> </ul>"},{"location":"guides/cpu_vs_gpu/","title":"CPU vs. GPU: Which to use for online data augmentation when training audio ML models?","text":"<p>When training an audio machine learning model that includes online data augmentation as part of the training pipeline, you can choose to run the transforms on CPU or GPU. While some libraries, such as torch-audiomentations, support GPU, audiomentations is CPU-only. So, which one is better? The answer is: it depends.</p>"},{"location":"guides/cpu_vs_gpu/#pros-of-using-cpu-only-libraries-like-audiomentations","title":"Pros of using CPU-only libraries like audiomentations","text":"<p>There are several advantages to using CPU-only data augmentation libraries like audiomentations:</p> <ul> <li>Easy to get started: Audiomentations is straightforward to install and use, which makes it a good choice for beginners or for those who want to quickly prototype an idea.</li> <li>No VRAM usage: These libraries don't use valuable VRAM, which you might want to allocate to your model with large batch sizes.</li> <li>Often fast enough to keep GPU(s) busy: Running augmentations on CPU on multiple threads in a data loader can be fast enough to keep your GPU(s) busy, which means that data loading doesn't become a bottleneck if the model's GPU utilization is already high. This can speed up model training.</li> <li>Larger selection of transforms: Some types of transforms, such as Mp3Compression, only have CPU implementations that can't run on GPU. This means that audiomentations provides a more extensive selection of transforms than torch-audiomentations.</li> <li>Independent of specific tensor processing libraries: Audiomentations is CPU-only, which means it is not tied to a specific tensor processing library like TensorFlow or PyTorch.</li> </ul>"},{"location":"guides/cpu_vs_gpu/#pros-of-running-audio-augmentation-transforms-on-gpus","title":"Pros of running audio augmentation transforms on GPU(s)","text":"<p>There are also advantages to running audio augmentation transforms on GPU, for example, with the help of torch-audiomentations :</p> <ul> <li>Faster processing: When your model is not big enough to utilize your GPU fully (in terms of processing capabilities and VRAM), running transforms on GPU can make sense, especially when the transforms are much faster on GPU than on CPU. An example of this is convolution, which can be used for applying room reverb or various filters.</li> <li>Can speed up training: If running the data loader becomes a bottleneck when running the transforms on CPU, running transforms on GPU(s) instead can speed up the training.</li> </ul> <p>In summary, whether to use CPU-only libraries like audiomentations or GPU-accelerated libraries like torch-audiomentations depends on the specific requirements of your model and the available hardware. If your model training pipeline doesn't utilize your GPU(s) fully, running transforms on GPU might be the best choice. However, if your model's GPU utilization is already very high, running the transforms on multiple CPU threads might be the best option. It boils down to checking where your bottleneck is. </p>"},{"location":"guides/multichannel_audio_array_shapes/","title":"Multichannel audio array shapes","text":"<p>When working with audio files in Python, you may encounter two main formats for representing the data, especially when you are dealing with stereo (or multichannel) audio. These formats correspond to the shape of the numpy ndarray that holds the audio data.</p>"},{"location":"guides/multichannel_audio_array_shapes/#1-channels-first-format","title":"1. Channels-first format","text":"<p>This format has the shape <code>(channels, samples)</code>. In the context of a stereo audio file, the number of channels would be 2 (for left and right), and samples are the individual data points in the audio file. For example, a stereo audio file with a duration of 1 second sampled at 44100 Hz would have a shape of <code>(2, 44100)</code>.</p> <p>This is the format expected by audiomentations when dealing with multichannel audio. If you provide multichannel audio data in a different format, a <code>WrongMultichannelAudioShape</code> exception will be raised.</p> <p>Note that <code>audiomentations</code> also supports mono audio, i.e. shape like <code>(1, samples)</code> or <code>(samples,)</code></p>"},{"location":"guides/multichannel_audio_array_shapes/#2-channels-last-format","title":"2. Channels-last format","text":"<p>This format has the shape <code>(samples, channels)</code>. Using the same stereo file example as above, the shape would be <code>(44100, 2)</code>. This format is commonly returned by the <code>soundfile</code> library when loading a stereo wav file, because channels last is the inherent data layout of a stereo wav file. This layout is the default in stereo wav files because it facilitates streaming audio, where data must be read and played back sequentially.</p>"},{"location":"guides/multichannel_audio_array_shapes/#loading-audio-with-different-libraries","title":"Loading audio with different libraries","text":"<p>Different libraries in Python may return audio data in different formats. For instance, <code>librosa</code> by default returns a mono ndarray, whereas <code>soundfile</code> will return a multichannel ndarray in channels-last format when loading a stereo wav file.</p> <p>Here is an example of how to load a file with each:</p> <pre><code>import librosa\nimport soundfile as sf\n\n# Librosa, mono\ny, sr = librosa.load(\"stereo_audio_example.wav\", sr=None, mono=True)\nprint(y.shape)  # (117833,)\n\n# Librosa, multichannel\ny, sr = librosa.load(\"stereo_audio_example.wav\", sr=None, mono=False)\nprint(y.shape)  # (2, 117833)\n\n# Soundfile\ny, sr = sf.read(\"stereo_audio_example.wav\")\nprint(y.shape)  # (117833, 2)\n</code></pre>"},{"location":"guides/multichannel_audio_array_shapes/#converting-between-formats","title":"Converting between formats","text":"<p>If you have audio data in the channels-last format but need it in channels-first format, you can easily convert it using the transpose operation of numpy ndarrays:</p> <pre><code>import numpy as np\n\n# Assuming y is your audio data in channels-last format\ny_transposed = np.transpose(y)\n\n# Alternative, shorter syntax:\ny_transposed = y.T\n</code></pre> <p>Now, <code>y_transposed</code> will be in channels-first format and can be used with <code>audiomentations</code>.</p> <p>However, there is a gotcha. Transposing the array as shown above does not change the underlying layout of the data in memory. Some audio processing libraries, especially ones that are written in C, C++ or Rust, might assume that the given NDArray is C-contiguous. If it is not C-contiguous, the code might still run without errors (depending on implementation), but your processed stereo audio might sound like it is played back at half speed, and there is a discrepancy between the left and the right channel. If you are passing audio to a function that assumes a C-contiguous data layout, you can use <code>np.ascontiguousarray</code> to make it C-contiguous:</p> <pre><code>y_transposed_contiguous = np.ascontiguousarray(y_transposed)\n</code></pre>"},{"location":"guides/transform_parameters/","title":"Transform parameters","text":""},{"location":"guides/transform_parameters/#how-to-obtain-the-chosen-parameters-after-calling-a-transform","title":"How to obtain the chosen parameters after calling a transform","text":"<p>You can access the <code>parameters</code> property of a transform. Code example:</p> <pre><code>from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\nimport numpy as np\n\naugment = Compose([\n    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n    Shift(p=0.5),\n])\n\n# Generate 2 seconds of dummy audio for the sake of example\nsamples = np.random.uniform(low=-0.2, high=0.2, size=(32000,)).astype(np.float32)\n\n# Augment/transform/perturb the audio data\naugmented_samples = augment(samples=samples, sample_rate=16000)\n\nfor transform in augment.transforms:\n    print(f\"{transform.__class__.__name__}: {transform.parameters}\")\n</code></pre> <p>When running the example code above, it may print something like this: <pre><code>AddGaussianNoise: {'should_apply': True, 'amplitude': 0.0027702725003923272}\nTimeStretch: {'should_apply': True, 'rate': 1.158377360016495}\nPitchShift: {'should_apply': False}\nShift: {'should_apply': False}\n</code></pre></p>"},{"location":"guides/transform_parameters/#how-to-use-apply-a-transform-with-the-same-parameters-to-multiple-inputs","title":"How to use apply a transform with the same parameters to multiple inputs","text":"<p>This technique can be useful if you want to transform e.g. a target sound in the same way as an input sound. Code example:</p> <pre><code>from audiomentations import Gain\nimport numpy as np\n\naugment = Gain(p=1.0)\n\nsamples = np.random.uniform(low=-0.2, high=0.2, size=(32000,)).astype(np.float32)\nsamples2 = np.random.uniform(low=-0.2, high=0.2, size=(32000,)).astype(np.float32)\n\naugmented_samples = augment(samples=samples, sample_rate=16000)\naugment.freeze_parameters()\nprint(augment.parameters)\naugmented_samples2 = augment(samples=samples2, sample_rate=16000)\nprint(augment.parameters)\naugment.unfreeze_parameters()\n</code></pre> <p>When running the example code above, it may print something like this:</p> <pre><code>{'should_apply': True, 'amplitude_ratio': 0.9688148624484364}\n{'should_apply': True, 'amplitude_ratio': 0.9688148624484364}\n</code></pre> <p>In other words, this means that both sounds (<code>samples</code> and <code>samples2</code>) were gained by the same amount</p>"},{"location":"waveform_transforms/add_background_noise/","title":"<code>AddBackgroundNoise</code>","text":"<p>Added in v0.9.0</p> <p>Mix in another sound, e.g. a background noise. Useful if your original sound is clean and you want to simulate an environment where background noise is present.</p> <p>Can also be used for mixup  when training classification/annotation models.</p> <p>A path to a file/folder with sound(s), or a list of file/folder paths, must be specified. These sounds should ideally be at least as long as the input sounds to be transformed. Otherwise, the background sound will be repeated, which may sound unnatural.</p> <p>Note that in the default case (<code>noise_rms=\"relative\"</code>) the gain of the added noise is relative to the signal level in the input. This implies that if the input is completely silent, no noise will be added.</p> <p>Optionally, the added noise sound can be transformed (with <code>noise_transform</code>) before it gets mixed in.</p> <p>Here are some examples of datasets that can be downloaded and used as background noise:</p> <ul> <li>https://github.com/karolpiczak/ESC-50#download </li> <li>https://github.com/microsoft/DNS-Challenge/ </li> </ul>"},{"location":"waveform_transforms/add_background_noise/#input-output-example","title":"Input-output example","text":"<p>Here we add some music to a speech recording, targeting a signal-to-noise ratio (SNR) of 5 Decibels (dB), which means that the speech (signal) is 5 dB louder than the music (noise).</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/add_background_noise/#usage-examples","title":"Usage examples","text":"Relative RMSAbsolute RMS <pre><code>from audiomentations import AddBackgroundNoise, PolarityInversion\n\ntransform = AddBackgroundNoise(\n    sounds_path=\"/path/to/folder_with_sound_files\",\n    min_snr_db=3.0,\n    max_snr_db=30.0,\n    noise_transform=PolarityInversion(),\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre> <pre><code>from audiomentations import AddBackgroundNoise, PolarityInversion\n\ntransform = AddBackgroundNoise(\n    sounds_path=\"/path/to/folder_with_sound_files\",\n    noise_rms=\"absolute\",\n    min_absolute_rms_db=-45.0,\n    max_absolute_rms_db=-15.0,\n    noise_transform=PolarityInversion(),\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/add_background_noise/#addbackgroundnoise-api","title":"AddBackgroundNoise API","text":"<code>sounds_path</code>: <code>Union[List[Path], List[str], Path, str]</code>  A path or list of paths to audio file(s) and/or folder(s) with audio files. Can be str or Path instance(s). The audio files given here are supposed to be background noises. <code>min_snr_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>3.0</code>. Minimum signal-to-noise ratio in dB. Is only used if <code>noise_rms</code> is set to <code>\"relative\"</code> <code>max_snr_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>30.0</code>. Maximum signal-to-noise ratio in dB. Is only used if <code>noise_rms</code> is set to <code>\"relative\"</code> <code>min_snr_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>min_snr_db</code> instead <code>max_snr_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>max_snr_db</code> instead <code>noise_rms</code>: <code>str</code> \u2022 choices: <code>\"absolute\"</code>, <code>\"relative\"</code>  Default: <code>\"relative\"</code>. Defines how the background noise will be added to the audio input. If the chosen option is <code>\"relative\"</code>, the root mean square (RMS) of the added noise will be proportional to the RMS of the input sound. If the chosen option is <code>\"absolute\"</code>, the background noise will have an RMS independent of the rms of the input audio file <code>min_absolute_rms_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-45.0</code>. Is only used if <code>noise_rms</code> is set to <code>\"absolute\"</code>. It is the minimum RMS value in dB that the added noise can take. The lower the RMS is, the lower the added sound will be. <code>max_absolute_rms_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-15.0</code>. Is only used if <code>noise_rms</code> is set to <code>\"absolute\"</code>. It is the maximum RMS value in dB that the added noise can take. Note that this value can not exceed 0. <code>min_absolute_rms_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>min_absolute_rms_db</code> instead <code>max_absolute_rms_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>max_absolute_rms_in_db</code> instead <code>noise_transform</code>: <code>Optional[Callable[[NDArray[np.float32], int], NDArray[np.float32]]]</code>  Default: <code>None</code>. A callable waveform transform (or composition of transforms) that gets applied to the noise before it gets mixed in. The callable is expected to input audio waveform (numpy array) and sample rate (int). <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform. <code>lru_cache_size</code>: <code>int</code>  Default: <code>2</code>. Maximum size of the LRU cache for storing noise files in memory"},{"location":"waveform_transforms/add_background_noise/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/add_background_noise.py </p>"},{"location":"waveform_transforms/add_color_noise/","title":"<code>AddColorNoise</code>","text":"<p>Added in v0.35.0</p> <p>Mix in noise with color, optionally weighted by an A-weighting  curve. When <code>f_decay=0</code>, this is equivalent to <code>AddGaussianNoise</code>. Otherwise, see: Colors of Noise .</p>"},{"location":"waveform_transforms/add_color_noise/#addcolornoise-api","title":"AddColorNoise API","text":"<code>min_snr_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>5.0</code>. Minimum signal-to-noise ratio in dB. A lower number means more noise. <code>max_snr_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>40.0</code>. Maximum signal-to-noise ratio in dB. A greater number means less noise. <code>min_f_decay</code>: <code>float</code> \u2022 unit: Decibels/octave  Default: <code>-6.0</code>. Minimum noise decay in dB per octave. <code>max_f_decay</code>: <code>float</code> \u2022 unit: Decibels/octave  Default: <code>6.0</code>. Maximum noise decay in dB per octave. <p>Those values can be chosen from the following table:</p> Colour <code>f_decay</code> (dB/octave) pink -3.01 brown/brownian -6.02 red -6.02 blue 3.01 azure 3.01 violet 6.02 white 0.0 <p>See Colors of noise  on Wikipedia about those values.</p> <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform. <code>p_apply_a_weighting</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.0</code>. The probability of additionally weighting the transform using an <code>A-weighting</code> curve. <code>n_fft</code>: <code>int</code>  Default: <code>128</code>. The number of points the decay curve is computed (for coloring white noise)."},{"location":"waveform_transforms/add_color_noise/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/add_color_noise.py </p>"},{"location":"waveform_transforms/add_gaussian_noise/","title":"<code>AddGaussianNoise</code>","text":"<p>Added in v0.1.0</p> <p>Add gaussian noise to the samples</p>"},{"location":"waveform_transforms/add_gaussian_noise/#input-output-example","title":"Input-output example","text":"<p>Here we add some gaussian noise (with amplitude 0.01) to a speech recording.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/add_gaussian_noise/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import AddGaussianNoise\n\ntransform = AddGaussianNoise(\n    min_amplitude=0.001,\n    max_amplitude=0.015,\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/add_gaussian_noise/#addgaussiannoise-api","title":"AddGaussianNoise API","text":"<code>min_amplitude</code>: <code>float</code> \u2022 unit: linear amplitude  Default: <code>0.001</code>. Minimum noise amplification factor. <code>max_amplitude</code>: <code>float</code> \u2022 unit: linear amplitude  Default: <code>0.015</code>. Maximum noise amplification factor. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/add_gaussian_noise/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/add_gaussian_noise.py </p>"},{"location":"waveform_transforms/add_gaussian_snr/","title":"<code>AddGaussianSNR</code>","text":"<p>Added in v0.7.0</p> <p>The <code>AddGaussianSNR</code> transform injects Gaussian noise into an audio signal. It applies a Signal-to-Noise Ratio (SNR) that is chosen randomly from a uniform distribution on the Decibel scale. This choice is consistent with the nature of human hearing, which is logarithmic rather than linear.</p> <p>SNR is a common measure used in science and engineering to compare the level of a desired signal to the level of noise. In the context of audio, the signal is the meaningful sound that you're interested in, like a person's voice, music, or other audio content, while the noise is unwanted sound that can interfere with the signal.</p> <p>The SNR quantifies the ratio of the power of the signal to the power of the noise. The higher the SNR, the less the noise is present in relation to the signal.</p> <p>Gaussian noise, a kind of white noise, is a type of statistical noise where the amplitude of the noise signal follows a Gaussian distribution. This means that most of the samples are close to the mean (zero), and fewer of them are farther away. It's called Gaussian noise due to its characteristic bell-shaped Gaussian distribution.</p> <p>Gaussian noise is similar to the sound of a radio or TV tuned to a nonexistent station: a kind of constant, uniform hiss or static.</p>"},{"location":"waveform_transforms/add_gaussian_snr/#input-output-example","title":"Input-output example","text":"<p>Here we add some gaussian noise (with SNR = 16 dB) to a speech recording.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/add_gaussian_snr/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import AddGaussianSNR\n\ntransform = AddGaussianSNR(\n    min_snr_db=5.0,\n    max_snr_db=40.0,\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/add_gaussian_snr/#addgaussiansnr-api","title":"AddGaussianSNR API","text":"<code>min_snr_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>5.0</code>. Minimum signal-to-noise ratio in dB. A lower number means more noise. <code>max_snr_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>40.0</code>. Maximum signal-to-noise ratio in dB. A greater number means less noise. <code>min_snr_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>min_snr_db</code> instead <code>max_snr_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>max_snr_db</code> instead <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/add_gaussian_snr/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/add_gaussian_snr.py </p>"},{"location":"waveform_transforms/add_short_noises/","title":"<code>AddShortNoises</code>","text":"<p>Added in v0.9.0</p> <p>Mix in various (bursts of overlapping) sounds with random pauses between. Useful if your original sound is clean and you want to simulate an environment where short noises sometimes occur.</p> <p>A folder of (noise) sounds to be mixed in must be specified.</p>"},{"location":"waveform_transforms/add_short_noises/#input-output-example","title":"Input-output example","text":"<p>Here we add some short noise sounds to a voice recording.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/add_short_noises/#usage-examples","title":"Usage examples","text":"Noise RMS relative to whole inputAbsolute RMS <pre><code>from audiomentations import AddShortNoises, PolarityInversion\n\ntransform = AddShortNoises(\n    sounds_path=\"/path/to/folder_with_sound_files\",\n    min_snr_db=3.0,\n    max_snr_db=30.0,\n    noise_rms=\"relative_to_whole_input\",\n    min_time_between_sounds=2.0,\n    max_time_between_sounds=8.0,\n    noise_transform=PolarityInversion(),\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre> <pre><code>from audiomentations import AddShortNoises, PolarityInversion\n\ntransform = AddShortNoises(\n    sounds_path=\"/path/to/folder_with_sound_files\",\n    min_absolute_noise_rms_db=-50.0,\n    max_absolute_noise_rms_db=-20.0,        \n    noise_rms=\"absolute\",\n    min_time_between_sounds=2.0,\n    max_time_between_sounds=8.0,\n    noise_transform=PolarityInversion(),\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/add_short_noises/#addshortnoises-api","title":"AddShortNoises API","text":"<code>sounds_path</code>: <code>Union[List[Path], List[str], Path, str]</code>  A path or list of paths to audio file(s) and/or folder(s) with audio files. Can be str or Path instance(s). The audio files given here are supposed to be (short) noises. <code>min_snr_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>min_snr_db</code> instead <code>max_snr_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>max_snr_db</code> instead <code>min_snr_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-6.0</code>. Minimum signal-to-noise ratio in dB. A lower value means the added sounds/noises will be louder. This gets ignored if <code>noise_rms</code> is set to <code>\"absolute\"</code>. <code>max_snr_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>18.0</code>. Maximum signal-to-noise ratio in dB. A lower value means the added sounds/noises will be louder. This gets ignored if <code>noise_rms</code> is set to <code>\"absolute\"</code>. <code>min_time_between_sounds</code>: <code>float</code> \u2022 unit: seconds  Default: <code>2.0</code>. Minimum pause time (in seconds) between the added sounds/noises <code>max_time_between_sounds</code>: <code>float</code> \u2022 unit: seconds  Default: <code>8.0</code>. Maximum pause time (in seconds) between the added sounds/noises <code>noise_rms</code>: <code>str</code> \u2022 choices: <code>\"absolute\"</code>, <code>\"relative\"</code>, <code>\"relative_to_whole_input\"</code> <p> Default: <code>\"relative_to_whole_input\"</code> (since v0.29.0)</p> <p>This parameter defines how the noises will be added to the audio input.</p> <ul> <li><code>\"relative\"</code>: the RMS value of the added noise will be proportional to the RMS value of     the input sound calculated only for the region where the noise is added.</li> <li><code>\"absolute\"</code>: the added noises will have an RMS independent of the RMS of the input audio     file.</li> <li><code>\"relative_to_whole_input\"</code>: the RMS of the added noises will be     proportional to the RMS of the whole input sound.</li> </ul> <code>min_absolute_noise_rms_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-50.0</code>. Is only used if <code>noise_rms</code> is set to <code>\"absolute\"</code>. It is the minimum RMS value in dB that the added noise can take. The lower the RMS is, the lower will the added sound be. <code>max_absolute_noise_rms_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-20.0</code>. Is only used if <code>noise_rms</code> is set to <code>\"absolute\"</code>. It is the maximum RMS value in dB that the added noise can take. Note that this value can not exceed 0. <code>add_all_noises_with_same_level</code>: <code>bool</code>  Default: <code>False</code>. Whether to add all the short noises (within one audio snippet) with the same SNR. If <code>noise_rms</code> is set to <code>\"absolute\"</code>, the RMS is used instead of SNR. The target SNR (or RMS) will change every time the parameters of the transform are randomized. <code>include_silence_in_noise_rms_estimation</code>: <code>bool</code>  Default: <code>True</code>. It chooses how the RMS of the noises to be added will be calculated. If this option is set to False, the silence in the noise files will be disregarded in the RMS calculation. It is useful for non-stationary noises where silent periods occur. <code>burst_probability</code>: <code>float</code>  Default: <code>0.22</code>. For every noise that gets added, there is a probability of adding an extra burst noise that overlaps with the noise. This parameter controls that probability. <code>min_pause_factor_during_burst</code> and <code>max_pause_factor_during_burst</code> control the amount of overlap. <code>min_pause_factor_during_burst</code>: <code>float</code>  Default: <code>0.1</code>. Min value of how far into the current sound (as fraction) the burst sound should start playing. The value must be greater than 0. <code>max_pause_factor_during_burst</code>: <code>float</code>  Default: <code>1.1</code>. Max value of how far into the current sound (as fraction) the burst sound should start playing. The value must be greater than 0. <code>min_fade_in_time</code>: <code>float</code> \u2022 unit: seconds  Default: <code>0.005</code>. Min noise fade in time in seconds. Use a value larger than 0 to avoid a \"click\" at the start of the noise. <code>max_fade_in_time</code>: <code>float</code> \u2022 unit: seconds  Default: <code>0.08</code>. Max noise fade in time in seconds. Use a value larger than 0 to avoid a \"click\" at the start of the noise. <code>min_fade_out_time</code>: <code>float</code> \u2022 unit: seconds  Default: <code>0.01</code>. Min sound/noise fade out time in seconds. Use a value larger than 0 to avoid a \"click\" at the end of the sound/noise. <code>max_fade_out_time</code>: <code>float</code> \u2022 unit: seconds  Default: <code>0.1</code>. Max sound/noise fade out time in seconds. Use a value larger than 0 to avoid a \"click\" at the end of the sound/noise. <code>signal_gain_in_db_during_noise</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0. Use <code>signal_gain_db_during_noise</code> instead <code>signal_gain_db_during_noise</code>: <code>float</code> \u2022 unit: Decibel <p> Default: <code>0.0</code>. Gain applied to the signal during a short noise. When fading the signal to the custom gain, the same fade times are used as for the noise, so it's essentially cross-fading. The default value (0.0) means the signal will not be gained. If set to a very low value, e.g. -100.0, this feature could be used for completely replacing the signal with the noise. This could be relevant in some use cases, for example:</p> <ul> <li>replace the signal with another signal of a similar class (e.g. replace some     speech with a cough)</li> <li>simulate an ECG off-lead condition (electrodes are temporarily disconnected)</li> </ul> <code>noise_transform</code>: <code>Optional[Callable[[NDArray[np.float32], int], NDArray[np.float32]]]</code>  Default: <code>None</code>. A callable waveform transform (or composition of transforms) that gets applied to noises before they get mixed in. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform. <code>lru_cache_size</code>: <code>int</code>  Default: <code>64</code>. Maximum size of the LRU cache for storing noise files in memory"},{"location":"waveform_transforms/add_short_noises/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/add_short_noises.py </p>"},{"location":"waveform_transforms/adjust_duration/","title":"<code>AdjustDuration</code>","text":"<p>Added in v0.30.0</p> <p>Trim or pad the audio to the specified length/duration in samples or seconds. If the input sound is longer than the target duration, pick a random offset and crop the sound to the target duration. If the input sound is shorter than the target duration, pad the sound so the duration matches the target duration.</p> <p>This transform can be useful if you need audio with constant length, e.g. as input to a machine learning model. The reason for varying audio clip lengths can be e.g.</p> <ul> <li>the nature of the audio dataset (different audio clips have different lengths)</li> <li>data augmentation transforms that change the lengths (e.g. time stretching or  convolving with impulse responses without cutting the tail)</li> </ul>"},{"location":"waveform_transforms/adjust_duration/#input-output-example","title":"Input-output example","text":"<p>Here we input an audio clip and remove a part of the start and the end, so the length of the result matches the specified target length.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/adjust_duration/#usage-examples","title":"Usage examples","text":"Target length in samplesTarget duration in seconds <pre><code>from audiomentations import AdjustDuration\n\ntransform = AdjustDuration(duration_samples=60000, p=1.0)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre> <pre><code>from audiomentations import AdjustDuration\n\ntransform = AdjustDuration(duration_seconds=3.75, p=1.0)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/adjust_duration/#adjustduration-api","title":"AdjustDuration API","text":"<code>duration_samples</code>: <code>int</code> \u2022 range: [0, \u221e)  Target duration in number of samples. <code>duration_seconds</code>: <code>float</code> \u2022 range: [0.0, \u221e)  Target duration in seconds. <code>padding_mode</code>: <code>str</code> \u2022 choices: <code>\"silence\"</code>, <code>\"wrap\"</code>, <code>\"reflect\"</code>  Default: <code>\"silence\"</code>. Padding mode. Only used when audio input is shorter than the target duration. * <code>\"silence\"</code>: Pads with zeros (silence). * <code>\"wrap\"</code>: Pads by wrapping the existing audio content. * <code>\"reflect\"</code>: Pads by reflecting the audio at the boundaries. <code>padding_position</code>: <code>str</code> \u2022 choices: <code>\"start\"</code>, <code>\"end\"</code>  Default: <code>\"end\"</code>. The position of the inserted/added padding. Only used when audio input is shorter than the target duration. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/adjust_duration/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/adjust_duration.py </p>"},{"location":"waveform_transforms/air_absorption/","title":"<code>AirAbsorption</code>","text":"<p>Added in v0.25.0</p> <p>A lowpass-like filterbank with variable octave attenuation that simulates attenuation of high frequencies due to air absorption. This transform is parametrized by temperature, humidity, and the distance between audio source and microphone.</p> <p>This is not a scientifically accurate transform but basically applies a uniform filterbank with attenuations given by:</p> <p><code>att = exp(- distance * absorption_coefficient)</code></p> <p>where <code>distance</code> is the microphone-source assumed distance in meters and <code>absorption_coefficient</code> is adapted from a lookup table by pyroomacoustics. It can also be seen as a lowpass filter with variable octave attenuation.</p> <p>Note that since this transform mostly affects high frequencies, it is only suitable for audio with sufficiently high sample rate, like 32 kHz and above.</p> <p>Note also that this transform only \"simulates\" the damping of high frequencies, and does not attenuate according to the distance law. Gain augmentation needs to be done separately.</p>"},{"location":"waveform_transforms/air_absorption/#input-output-example","title":"Input-output example","text":"<p>Here we input a high-quality speech recording and apply <code>AirAbsorption</code> with an air temperature of 20 degrees celsius, 70% humidity and a distance of 20 meters. One can see clearly in the spectrogram that the highs, especially above ~13 kHz, are rolled off in the output, but it may require a quiet room and some concentration to hear it clearly in the audio comparison.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/air_absorption/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import AirAbsorption\n\ntransform = AirAbsorption(\n    min_distance=10.0,\n    max_distance=50.0,\n    p=1.0,\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=48000)\n</code></pre>"},{"location":"waveform_transforms/air_absorption/#airabsorption-api","title":"AirAbsorption API","text":"<code>min_temperature</code>: <code>float</code> \u2022 unit: Celsius \u2022 choices: [10.0, 20.0]  Default: <code>10.0</code>. Minimum temperature in Celsius (can take a value of either 10.0 or 20.0) <code>max_temperature</code>: <code>float</code> \u2022 unit: Celsius \u2022 choices: [10.0, 20.0]  Default: <code>20.0</code>. Maximum temperature in Celsius (can take a value of either 10.0 or 20.0) <code>min_humidity</code>: <code>float</code> \u2022 unit: percent \u2022 range: [30.0, 90.0]  Default: <code>30.0</code>. Minimum humidity in percent (between 30.0 and 90.0) <code>max_humidity</code>: <code>float</code> \u2022 unit: percent \u2022 range: [30.0, 90.0]  Default: <code>90.0</code>. Maximum humidity in percent (between 30.0 and 90.0) <code>min_distance</code>: <code>float</code> \u2022 unit: meters \u2022 range: (0.0, 2500.0]  Default: <code>10.0</code>. Minimum microphone-source distance in meters. <code>max_distance</code>: <code>float</code> \u2022 unit: meters \u2022 range: (0.0, 2500.0]  Default: <code>100.0</code>. Maximum microphone-source distance in meters. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/air_absorption/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/air_absorption.py </p>"},{"location":"waveform_transforms/aliasing/","title":"<code>Aliasing</code>","text":"<p>Added in v0.35.0</p> <p>Downsample the audio to a lower sample rate by linear interpolation, without low-pass filtering it first, resulting in aliasing artifacts. You get aliasing artifacts when there is high-frequency audio in the input audio that falls above the Nyquist frequency of the chosen target sample rate. Audio with frequencies above the Nyquist frequency cannot be reproduced accurately and gets \"reflected\"/mirrored to other frequencies. The aliasing artifacts replace the original high-frequency signals. The result can be described as coarse and metallic.</p> <p>After the downsampling, the signal gets upsampled to the original sample rate again, so the length of the output becomes the same as the length of the input.</p> <p>For more information, see</p> <ul> <li>Sample rate reduction  on Wikipedia</li> <li>Intro to downsampling  by NTNU, Department of Music, Music Technology. Note: that article describes a slightly different downsampling technique, called sample-and-hold, while <code>Aliasing</code> in audiomentations currently implements linear interpolation. However, both methods lead to aliasing artifacts.</li> </ul>"},{"location":"waveform_transforms/aliasing/#input-output-example","title":"Input-output example","text":"<p>Here we target a sample rate of 12000 Hz. Note the vertical mirroring in the spectrogram in the transformed sound.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/aliasing/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import Aliasing\n\ntransform = Aliasing(min_sample_rate=8000, max_sample_rate=30000, p=1.0)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=44100)\n</code></pre>"},{"location":"waveform_transforms/aliasing/#aliasing-api","title":"Aliasing API","text":"<code>min_sample_rate</code>: <code>int</code> \u2022 unit: Hz \u2022 range: [2, \u221e)  Minimum target sample rate to downsample to <code>max_sample_rate</code>: <code>int</code> \u2022 unit: Hz \u2022 range: [2, \u221e)  Maximum target sample rate to downsample to <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/aliasing/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/aliasing.py </p>"},{"location":"waveform_transforms/apply_impulse_response/","title":"<code>ApplyImpulseResponse</code>","text":"<p>Added in v0.7.0</p> <p>This transform convolves the audio with a randomly selected (room) impulse response file.</p> <p><code>ApplyImpulseResponse</code> is commonly used as a data augmentation technique that adds realistic-sounding reverb to recordings. This can for example make denoisers and speech recognition systems more robust to different acoustic environments and distances between the sound source and the microphone. It could also be used to generate roomy audio examples for the training of dereverberation models.</p> <p>Convolution with an impulse response is a powerful technique in signal processing that can be employed to emulate the acoustic characteristics of specific environments or devices. This process can transform a dry recording, giving it the sonic signature of being played in a specific location or through a particular device.</p> <p>What is an impulse response? An impulse response (IR) captures the unique acoustical signature of a space or object. It's essentially a recording of how a specific environment or system responds to an impulse (a short, sharp sound). By convolving an audio signal with an impulse response, we can simulate how that signal would sound in the captured environment.</p> <p>Note that some impulse responses, especially those captured in larger spaces or from specific equipment, can introduce a noticeable delay when convolved with an audio signal. In some applications, this delay is a desirable property. However, in some other applications, the convolved audio should not have a delay compared to the original audio. If this is the case for you, you can align the audio afterwards with fast-align-audio , for example.</p> <p>Impulse responses can be created using e.g. http://tulrich.com/recording/ir_capture/ </p> <p>Some datasets of impulse responses are publicly available:</p> <ul> <li>EchoThief  containing 115 impulse responses acquired in a  wide range of locations.</li> <li>The MIT McDermott  dataset  containing 271 impulse responses acquired in everyday places.</li> <li>RoyJames/room-impulse-responses  - a list of publicly available acoustic/room impulse response (AIR/RIR) datasets</li> </ul> <p>Impulse responses are represented as audio (ideally wav) files in the given <code>ir_path</code>.</p> <p>Another thing worth checking is that your IR files have the same sample rate as your audio inputs. Why? Because if they have different sample rates, the internal resampling will slow down execution, and because some high frequencies may get lost.</p>"},{"location":"waveform_transforms/apply_impulse_response/#input-output-example","title":"Input-output example","text":"<p>Here we make a dry speech recording quite reverberant by convolving it with a room impulse response</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/apply_impulse_response/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import ApplyImpulseResponse\n\ntransform = ApplyImpulseResponse(ir_path=\"/path/to/sound_folder\", p=1.0)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=48000)\n</code></pre>"},{"location":"waveform_transforms/apply_impulse_response/#applyimpulseresponse-api","title":"ApplyImpulseResponse API","text":"<code>ir_path</code>: <code>Union[List[Path], List[str], str, Path]</code>  A path or list of paths to audio file(s) and/or folder(s) with audio files. Can be <code>str</code> or <code>Path</code> instance(s). The audio files given here are supposed to be (room) impulse responses. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform. <code>lru_cache_size</code>: <code>int</code>  Default: <code>128</code>. Maximum size of the LRU cache for storing impulse response files in memory. <code>leave_length_unchanged</code>: <code>bool</code>  Default: <code>True</code>. When set to <code>True</code>, the tail of the sound (e.g. reverb at the end) will be chopped off so that the length of the output is equal to the length of the input."},{"location":"waveform_transforms/apply_impulse_response/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/apply_impulse_response.py </p>"},{"location":"waveform_transforms/band_pass_filter/","title":"<code>BandPassFilter</code>","text":"<p>Added in v0.18.0, updated in v0.21.0</p> <p>Apply band-pass filtering to the input audio. Filter steepness (6/12/18... dB / octave) is parametrized. Can also be set for zero-phase filtering (will result in a 6 dB drop at cutoffs).</p>"},{"location":"waveform_transforms/band_pass_filter/#input-output-example","title":"Input-output example","text":"<p>Here we input a high-quality speech recording and apply <code>BandPassFilter</code> with a center frequency of 2500 Hz and a bandwidth fraction of 0.8, which means that the bandwidth in this example is 2000 Hz, so the low frequency cutoff is 1500 Hz and the high frequency cutoff is 3500 Hz. One can see in the spectrogram that the high and the low frequencies are both attenuated in the output. If you listen to the audio example, you might notice that the transformed output almost sounds like a phone call from the time when phone audio was narrowband and mostly contained frequencies between ~300 and ~3400 Hz.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/band_pass_filter/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import BandPassFilter\n\ntransform = BandPassFilter(min_center_freq=100.0, max_center_freq=6000, p=1.0)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=48000)\n</code></pre>"},{"location":"waveform_transforms/band_pass_filter/#bandpassfilter-api","title":"BandPassFilter API","text":"<code>min_center_freq</code>: <code>float</code> \u2022 unit: hertz  Default: <code>200.0</code>. Minimum center frequency in hertz <code>max_center_freq</code>: <code>float</code> \u2022 unit: hertz  Default: <code>4000.0</code>. Maximum center frequency in hertz <code>min_bandwidth_fraction</code>: <code>float</code> \u2022 range: [0.0, 2.0]  Default: <code>0.5</code>. Minimum bandwidth relative to center frequency <code>max_bandwidth_fraction</code>: <code>float</code> \u2022 range: [0.0, 2.0]  Default: <code>1.99</code>. Maximum bandwidth relative to center frequency <code>min_rolloff</code>: <code>int</code> \u2022 unit: Decibels/octave  Default: <code>12</code>. Minimum filter roll-off (in dB/octave). Must be a multiple of 6 (or 12 if <code>zero_phase</code> is <code>True</code>) <code>max_rolloff</code>: <code>int</code> \u2022 unit: Decibels/octave  Default: <code>24</code>. Maximum filter roll-off (in dB/octave) Must be a multiple of 6 (or 12 if <code>zero_phase</code> is <code>True</code>) <code>zero_phase</code>: <code>bool</code>  Default: <code>False</code>. Whether filtering should be zero phase. When this is set to <code>True</code>, it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is twice as slow as the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to <code>True</code>. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/band_pass_filter/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/band_pass_filter.py </p>"},{"location":"waveform_transforms/band_stop_filter/","title":"<code>BandStopFilter</code>","text":"<p>Added in v0.21.0</p> <p>Apply band-stop filtering to the input audio. Also known as notch filter or band reject filter. It relates to the frequency mask idea in the SpecAugment paper . Center frequency gets picked in mel space, so it is somewhat aligned with human hearing, which is not linear. Filter steepness (6/12/18... dB / octave) is parametrized. Can also be set for zero-phase filtering (will result in a 6 dB drop at cutoffs).</p> <p>Applying band-stop filtering as data augmentation during model training can aid in preventing overfitting to specific frequency relationships, helping to make the model robust to diverse audio environments and scenarios, where frequency losses can occur.</p>"},{"location":"waveform_transforms/band_stop_filter/#input-output-example","title":"Input-output example","text":"<p>Here we input a speech recording and apply <code>BandStopFilter</code> with a center frequency of 2500 Hz and a bandwidth fraction of 0.8, which means that the bandwidth in this example is 2000 Hz, so the low frequency cutoff is 1500 Hz and the high frequency cutoff is 3500 Hz. One can see in the spectrogram of the transformed sound that the band stop filter has attenuated this frequency range. If you listen to the audio example, you can hear that the timbre is different in the transformed sound than in the original.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/band_stop_filter/#bandstopfilter-api","title":"BandStopFilter API","text":"<code>min_center_freq</code>: <code>float</code> \u2022 unit: hertz  Default: <code>200.0</code>. Minimum center frequency in hertz <code>max_center_freq</code>: <code>float</code> \u2022 unit: hertz  Default: <code>4000.0</code>. Maximum center frequency in hertz <code>min_bandwidth_fraction</code>: <code>float</code>  Default: <code>0.5</code>. Minimum bandwidth fraction relative to center frequency <code>max_bandwidth_fraction</code>: <code>float</code>  Default: <code>1.99</code>. Maximum bandwidth fraction relative to center frequency <code>min_rolloff</code>: <code>int</code> \u2022 unit: Decibels/octave  Default: <code>12</code>. Minimum filter roll-off (in dB/octave). Must be a multiple of 6 (or 12 if <code>zero_phase</code> is <code>True</code>) <code>max_rolloff</code>: <code>int</code> \u2022 unit: Decibels/octave  Default: <code>24</code>. Maximum filter roll-off (in dB/octave) Must be a multiple of 6 (or 12 if <code>zero_phase</code> is <code>True</code>) <code>zero_phase</code>: <code>bool</code>  Default: <code>False</code>. Whether filtering should be zero phase. When this is set to <code>True</code>, it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is twice as slow as the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to <code>True</code>. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/band_stop_filter/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/band_stop_filter.py </p>"},{"location":"waveform_transforms/bit_crush/","title":"<code>BitCrush</code>","text":"<p>Added in v0.35.0</p> <p>Apply a bit crush effect to the audio by reducing the bit depth. In other words, it reduces the number of bits that can be used for representing each audio sample. This adds quantization noise, and affects dynamic range. This transform does not apply dithering.</p> <p>For more information, see</p> <ul> <li>Resolution reduction  on Wikipedia</li> <li>Intro to bit reduction  by NTNU, Department of Music, Music Technology</li> </ul>"},{"location":"waveform_transforms/bit_crush/#input-output-example","title":"Input-output example","text":"<p>Here we reduce the bit depth from 16 to 6 bits per sample</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/bit_crush/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import BitCrush\n\ntransform = BitCrush(min_bit_depth=5, max_bit_depth=14, p=1.0)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/bit_crush/#bitcrush-api","title":"BitCrush API","text":"<code>min_bit_depth</code>: <code>int</code> \u2022 unit: bits \u2022 range: [1, 32]  Minimum bit depth the audio will be \"converted\" to <code>max_bit_depth</code>: <code>int</code> \u2022 unit: bits \u2022 range: [1, 32]  Maximum bit depth the audio will be \"converted\" to <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/bit_crush/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/bit_crush.py </p>"},{"location":"waveform_transforms/clip/","title":"<code>Clip</code>","text":"<p>Added in v0.17.0</p> <p>Clip audio by specified values. e.g. set <code>a_min=-1.0</code> and <code>a_max=1.0</code> to ensure that no samples in the audio exceed that extent. This can be relevant for avoiding integer overflow or underflow (which results in unintended wrap distortion that can sound horrible) when exporting to e.g. 16-bit PCM wav.</p> <p>Another way of ensuring that all values stay between -1.0 and 1.0 is to apply <code>PeakNormalization</code>.</p> <p>This transform is different from <code>ClippingDistortion</code> in that it takes fixed values for clipping instead of clipping a random percentile of the samples. Arguably, this transform is not very useful for data augmentation. Instead, think of it as a very cheap and harsh limiter (for samples that exceed the allotted extent) that can sometimes be useful at the end of a data augmentation pipeline.</p>"},{"location":"waveform_transforms/clip/#clip-api","title":"Clip API","text":"<code>a_min</code>: <code>float</code>  Default: <code>-1.0</code>. Minimum value for clipping. <code>a_max</code>: <code>float</code>  Default: <code>1.0</code>. Maximum value for clipping. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/clip/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/clip.py </p>"},{"location":"waveform_transforms/clipping_distortion/","title":"<code>ClippingDistortion</code>","text":"<p>Added in v0.8.0</p> <p>Distort signal by clipping a random percentage of points</p> <p>The percentage of points that will be clipped is drawn from a uniform distribution between the two input parameters <code>min_percentile_threshold</code> and <code>max_percentile_threshold</code>. If for instance 30% is drawn, the samples are clipped if they're below the 15th or above the 85th percentile.</p>"},{"location":"waveform_transforms/clipping_distortion/#clippingdistortion-api","title":"ClippingDistortion API","text":"<code>min_percentile_threshold</code>: <code>int</code>  Default: <code>0</code>. A lower bound on the total percent of samples that will be clipped <code>max_percentile_threshold</code>: <code>int</code>  Default: <code>40</code>. An upper bound on the total percent of samples that will be clipped <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/clipping_distortion/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/clipping_distortion.py </p>"},{"location":"waveform_transforms/gain/","title":"<code>Gain</code>","text":"<p>Added in v0.11.0</p> <p>Multiply the audio by a random amplitude factor to reduce or increase the volume. This technique can help a model become somewhat invariant to the overall gain of the input audio.</p> <p>Warning: This transform can return samples outside the [-1, 1] range, which may lead to clipping or wrap distortion, depending on what you do with the audio in a later stage. See also https://en.wikipedia.org/wiki/Clipping_(audio)#Digital_clipping</p>"},{"location":"waveform_transforms/gain/#input-output-example","title":"Input-output example","text":"<p>Here we input a speech recording and apply a -8 dB gain.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/gain/#gain-api","title":"Gain API","text":"<code>min_gain_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>min_gain_db</code> instead <code>max_gain_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>max_gain_db</code> instead <code>min_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-12.0</code>. Minimum gain. <code>max_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>12.0</code>. Maximum gain. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/gain/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/gain.py </p>"},{"location":"waveform_transforms/gain_transition/","title":"<code>GainTransition</code>","text":"<p>Added in v0.22.0</p> <p>Gradually change the volume up or down over a random time span. Also known as fade in and fade out. The fade works on a logarithmic scale, which is natural to human hearing.</p> <p>The way this works is that it picks two gains: a first gain and a second gain. Then it picks a time range for the transition between those two gains. Note that this transition can start before the audio starts and/or end after the audio ends, so the output audio can start or end in the middle of a transition. The gain starts at the first gain and is held constant until the transition start. Then it transitions to the second gain. Then that gain is held constant until the end of the sound.</p>"},{"location":"waveform_transforms/gain_transition/#gaintransition-api","title":"GainTransition API","text":"<code>min_gain_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>min_gain_db</code> instead <code>max_gain_in_db</code>: <code>float</code> \u2022 unit: Decibel  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>max_gain_db</code> instead <code>min_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-24.0</code>. Minimum gain in dB. <code>max_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>6.0</code>. Maximum gain in dB. <code>min_duration</code>: <code>Union[float, int]</code> \u2022 unit: see <code>duration_unit</code>  Default: <code>0.2</code>. Minimum length of transition. <code>max_duration</code>: <code>Union[float, int]</code> \u2022 unit: see <code>duration_unit</code>  Default: <code>6.0</code>. Maximum length of transition. <code>duration_unit</code>: <code>str</code> \u2022 choices: <code>\"fraction\"</code>, <code>\"samples\"</code>, <code>\"seconds\"</code> <p> Default: <code>\"seconds\"</code>. Defines the unit of the value of <code>min_duration</code> and <code>max_duration</code>.</p> <ul> <li><code>\"fraction\"</code>: Fraction of the total sound length</li> <li><code>\"samples\"</code>: Number of audio samples</li> <li><code>\"seconds\"</code>: Number of seconds</li> </ul> <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/gain_transition/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/gain_transition.py </p>"},{"location":"waveform_transforms/high_pass_filter/","title":"<code>HighPassFilter</code>","text":"<p>Added in v0.18.0, updated in v0.21.0</p> <p>Apply high-pass filtering to the input audio of parametrized filter steepness (6/12/18... dB / octave). Can also be set for zero-phase filtering (will result in a 6 dB drop at cutoff).</p>"},{"location":"waveform_transforms/high_pass_filter/#input-output-example","title":"Input-output example","text":"<p>Here we input a high-quality speech recording and apply <code>HighPassFilter</code> with a cutoff frequency of 1000 Hz, a filter roll-off of 12 dB/octave and with <code>zero_phase=False</code>. One can see in the spectrogram below that the low frequencies (at the bottom) are attenuated in the output. This change is not immediately obvious when just looking at the spectrogram with linear frequency axis, but if you listen to the transformed sound, you'll immediately hear that all the bass/\"meat\"/warmth/body is gone.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/high_pass_filter/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import HighPassFilter\n\ntransform = HighPassFilter(min_cutoff_freq=200.0, max_cutoff_freq=1500.0, p=1.0)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=48000)\n</code></pre>"},{"location":"waveform_transforms/high_pass_filter/#highpassfilter-api","title":"HighPassFilter API","text":"<code>min_cutoff_freq</code>: <code>float</code> \u2022 unit: hertz \u2022 range: (0.0, <code>max_cutoff_freq</code>]  Default: <code>20.0</code>. Minimum cutoff frequency <code>max_cutoff_freq</code>: <code>float</code> \u2022 unit: hertz \u2022 range: [<code>min_cutoff_freq</code>, sample_rate/2)  Default: <code>2400.0</code>. Maximum cutoff frequency <code>min_rolloff</code>: <code>float</code> \u2022 unit: Decibels/octave  Default: <code>12</code>. Minimum filter roll-off (in dB/octave). Must be a multiple of 6 (or 12 if <code>zero_phase</code> is <code>True</code>) <code>max_rolloff</code>: <code>float</code> \u2022 unit: Decibels/octave  Default: <code>24</code>. Maximum filter roll-off (in dB/octave). Must be a multiple of 6 (or 12 if <code>zero_phase</code> is <code>True</code>) <code>zero_phase</code>: <code>bool</code>  Default: <code>False</code>. Whether filtering should be zero phase. When this is set to <code>True</code>, it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is twice as slow as the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to <code>True</code>. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/high_pass_filter/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/high_pass_filter.py </p>"},{"location":"waveform_transforms/high_shelf_filter/","title":"<code>HighShelfFilter</code>","text":"<p>Added in v0.21.0</p> <p>A high shelf filter is a filter that either boosts (increases amplitude) or cuts (decreases amplitude) frequencies above a certain center frequency. This transform applies a high-shelf filter at a specific center frequency in hertz. The gain at Nyquist frequency is controlled by <code>{min,max}_gain_db</code> (note: can be positive or negative!). Filter coefficients are taken from the W3 Audio EQ Cookbook </p>"},{"location":"waveform_transforms/high_shelf_filter/#highshelffilter-api","title":"HighShelfFilter API","text":"<code>min_center_freq</code>: <code>float</code> \u2022 unit: hertz  Default: <code>300.0</code>. The minimum center frequency of the shelving filter <code>max_center_freq</code>: <code>float</code> \u2022 unit: hertz  Default: <code>7500.0</code>. The maximum center frequency of the shelving filter <code>min_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-18.0</code>. The minimum gain at the Nyquist frequency <code>max_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>18.0</code>. The maximum gain at the Nyquist frequency <code>min_q</code>: <code>float</code> \u2022 range: (0.0, 1.0]  Default: <code>0.1</code>. The minimum quality factor Q. The higher the Q, the steeper the transition band will be. <code>max_q</code>: <code>float</code> \u2022 range: (0.0, 1.0]  Default: <code>0.999</code>. The maximum quality factor Q. The higher the Q, the steeper the transition band will be. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/high_shelf_filter/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/high_shelf_filter.py </p>"},{"location":"waveform_transforms/lambda/","title":"<code>Lambda</code>","text":"<p>Added in v0.26.0</p> <p>Apply a user-defined transform (callable) to the signal. The inspiration for this transform comes from albumentation's lambda transform. This allows one to have a little more fine-grained control over the operations in the context of a <code>Compose</code>, <code>OneOf</code> or <code>SomeOf</code></p>"},{"location":"waveform_transforms/lambda/#usage-example","title":"Usage example","text":"<pre><code>import random\n\nfrom audiomentations import Lambda, OneOf, Gain\n\n\ndef gain_only_left_channel(samples, sample_rate):\n    samples[0, :] *= random.uniform(0.8, 1.25)\n    return samples\n\n\ntransform = OneOf(\n    transforms=[Lambda(transform=gain_only_left_channel, p=1.0), Gain(p=1.0)]\n)\n\naugmented_sound = transform(my_stereo_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/lambda/#lambda-api","title":"Lambda API","text":"<code>transform</code>: <code>Callable</code>  A callable to be applied. It should input samples (ndarray), sample_rate (int) and optionally some user-defined keyword arguments. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform. <code>**kwargs</code>  Optional extra parameters passed to the callable transform"},{"location":"waveform_transforms/lambda/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/lambda_transform.py </p>"},{"location":"waveform_transforms/limiter/","title":"<code>Limiter</code>","text":"<p>Added in v0.26.0</p> <p>The <code>Limiter</code>, based on numpy-audio-limiter , is a straightforward audio transform that applies dynamic range compression. It is capable of limiting the audio signal based on certain parameters.</p> <ul> <li>The threshold determines the audio level above which the limiter kicks in.</li> <li>The attack time is how quickly the limiter kicks in once the audio signal starts exceeding the threshold.</li> <li>The release time determines how quickly the limiter stops working after the signal drops below the threshold.</li> </ul> <p> In audiomentations v0.35.0 and earlier, this transform introduced a delay in the signal, equivalent to a ~60% of the attack time. Starting from v0.36.0, the output is aligned with the input, i.e. no delay.</p> <p> Note: In audiomentations v0.42.0, the dependency for this transform changed from cylimiter  to numpy-audio-limiter , which is ~30% faster and easier to install for newer Python versions. The behavior stays the same, although there are minor numerical differences between the two.</p>"},{"location":"waveform_transforms/limiter/#input-output-example","title":"Input-output example","text":"<p>In this example we apply the limiter with a threshold that is 10 dB lower than the signal peak</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/limiter/#usage-examples","title":"Usage examples","text":"Threshold relative to signal peakAbsolute threshold <pre><code>from audiomentations import Limiter\n\ntransform = Limiter(\n    min_threshold_db=-16.0,\n    max_threshold_db=-6.0,\n    threshold_mode=\"relative_to_signal_peak\",\n    p=1.0,\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre> <pre><code>from audiomentations import Limiter\n\ntransform = Limiter(\n    min_threshold_db=-16.0,\n    max_threshold_db=-6.0,\n    threshold_mode=\"absolute\",\n    p=1.0,\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/limiter/#limiter-api","title":"Limiter API","text":"<code>min_threshold_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-24.0</code>. Minimum threshold <code>max_threshold_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-2.0</code>. Maximum threshold <code>min_attack</code>: <code>float</code> \u2022 unit: seconds  Default: <code>0.0005</code>. Minimum attack time <code>max_attack</code>: <code>float</code> \u2022 unit: seconds  Default: <code>0.025</code>. Maximum attack time <code>min_release</code>: <code>float</code> \u2022 unit: seconds  Default: <code>0.05</code>. Minimum release time <code>max_release</code>: <code>float</code> \u2022 unit: seconds  Default: <code>0.7</code>. Maximum release time <code>threshold_mode</code>: <code>str</code> \u2022 choices: <code>\"relative_to_signal_peak\"</code>, <code>\"absolute\"</code> <p> Default: <code>relative_to_signal_peak</code>. Specifies the mode for determining the threshold.</p> <ul> <li><code>\"relative_to_signal_peak\"</code> means the threshold is relative to peak of the signal.</li> <li><code>\"absolute\"</code> means the threshold is relative to 0 dBFS, so it doesn't depend  on the peak of the signal.</li> </ul> <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/limiter/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/limiter.py </p>"},{"location":"waveform_transforms/loudness_normalization/","title":"<code>LoudnessNormalization</code>","text":"<p>Added in v0.14.0, updated in v0.43.0</p> <p>Apply a constant amount of gain to match a specific loudness (in LUFS). This is an implementation of ITU-R BS.1770-4.</p> <p>For an explanation on LUFS, see https://en.wikipedia.org/wiki/LUFS </p> <p>See also the following web page for more info on audio loudness normalization:</p> <ul> <li>https://en.wikipedia.org/wiki/Audio_normalization </li> </ul> <p>Warning: This transform can return samples outside the [-1, 1] range, which may lead to clipping or wrap distortion, depending on what you do with the audio in a later stage. See also https://en.wikipedia.org/wiki/Clipping_(audio)#Digital_clipping </p>"},{"location":"waveform_transforms/loudness_normalization/#loudnessnormalization-api","title":"LoudnessNormalization API","text":"<code>min_lufs_in_db</code>: <code>float</code> \u2022 unit: LUFS  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>min_lufs</code> instead <code>max_lufs_in_db</code>: <code>float</code> \u2022 unit: LUFS  Deprecated as of v0.31.0, removed as of v0.38.0. Use <code>max_lufs</code> instead <code>min_lufs</code>: <code>float</code> \u2022 unit: LUFS  Default: <code>-31.0</code>. Minimum loudness target. <code>max_lufs</code>: <code>float</code> \u2022 unit: LUFS  Default: <code>-13.0</code>. Maximum loudness target. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/loudness_normalization/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/loudness_normalization.py </p>"},{"location":"waveform_transforms/low_pass_filter/","title":"<code>LowPassFilter</code>","text":"<p>Added in v0.18.0, updated in v0.21.0</p> <p>Apply low-pass filtering to the input audio of parametrized filter steepness (6/12/18... dB / octave). Can also be set for zero-phase filtering (will result in a 6 dB drop at cutoff).</p>"},{"location":"waveform_transforms/low_pass_filter/#lowpassfilter-api","title":"LowPassFilter API","text":"<code>min_cutoff_freq</code>: <code>float</code> \u2022 unit: hertz  Default: <code>150.0</code>. Minimum cutoff frequency <code>max_cutoff_freq</code>: <code>float</code> \u2022 unit: hertz  Default: <code>7500.0</code>. Maximum cutoff frequency <code>min_rolloff</code>: <code>int</code> \u2022 unit: Decibels/octave  Default: <code>12</code>. Minimum filter roll-off (in dB/octave). Must be a multiple of 6 (or 12 if <code>zero_phase</code> is <code>True</code>) <code>max_rolloff</code>: <code>int</code> \u2022 unit: Decibels/octave  Default: <code>24</code>. Maximum filter roll-off (in dB/octave) Must be a multiple of 6 (or 12 if <code>zero_phase</code> is <code>True</code>) <code>zero_phase</code>: <code>bool</code>  Default: <code>False</code>. Whether filtering should be zero phase. When this is set to <code>True</code>, it will not affect the phase of the input signal but will sound 3 dB lower at the cutoff frequency compared to the non-zero phase case (6 dB vs. 3 dB). Additionally, it is twice as slow as the non-zero phase case. If you absolutely want no phase distortions (e.g. want to augment an audio file with lots of transients, like a drum track), set this to <code>True</code>. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/low_pass_filter/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/low_pass_filter.py </p>"},{"location":"waveform_transforms/low_shelf_filter/","title":"<code>LowShelfFilter</code>","text":"<p>Added in v0.21.0</p> <p>A low shelf filter is a filter that either boosts (increases amplitude) or cuts (decreases amplitude) frequencies below a certain center frequency. This transform applies a low-shelf filter at a specific center frequency in hertz. The gain at DC frequency is controlled by <code>{min,max}_gain_db</code> (note: can be positive or negative!). Filter coefficients are taken from the W3 Audio EQ Cookbook </p>"},{"location":"waveform_transforms/low_shelf_filter/#lowshelffilter-api","title":"LowShelfFilter API","text":"<code>min_center_freq</code>: <code>float</code> \u2022 unit: hertz  Default: <code>50.0</code>. The minimum center frequency of the shelving filter <code>max_center_freq</code>: <code>float</code> \u2022 unit: hertz  Default: <code>4000.0</code>. The maximum center frequency of the shelving filter <code>min_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-18.0</code>. The minimum gain at DC (0 Hz) <code>max_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>18.0</code>. The maximum gain at DC (0 Hz) <code>min_q</code>: <code>float</code> \u2022 range: (0.0, 1.0]  Default: <code>0.1</code>. The minimum quality factor Q. The higher the Q, the steeper the transition band will be. <code>max_q</code>: <code>float</code> \u2022 range: (0.0, 1.0]  Default: <code>0.999</code>. The maximum quality factor Q. The higher the Q, the steeper the transition band will be. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/low_shelf_filter/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/low_shelf_filter.py </p>"},{"location":"waveform_transforms/mp3_compression/","title":"<code>Mp3Compression</code>","text":"<p>Added in v0.12.0, updated in v0.43.0</p> <p>Compress the audio using an MP3 encoder to lower the audio quality. This may help machine learning models deal with compressed, low-quality audio.</p> <p>This transform depends on fast-mp3-augment , lameenc  or pydub /ffmpeg.</p> <p>Starting with v0.42.0, the default backend is <code>\"fast-mp3-augment\"</code>, which performs the encode-decode round-trip entirely in memory and in parallel threads. This makes the transform significantly faster than the older <code>\"pydub\"</code> and <code>\"lameenc\"</code> backends and avoids writing temporary files to disk. Here's the result from a small benchmark that ran 3 short audio snippets (~7-9s) through each backend:</p> <p></p> <p>Note: When using <code>\"fast-mp3-augment\"</code> or <code>\"lameenc\"</code>, these are the only supported sample rates: 8000, 11025, 12000, 16000, 22050, 24000, 32000, 44100, 48000</p>"},{"location":"waveform_transforms/mp3_compression/#input-output-example","title":"Input-output example","text":"<p>Here we input a high-quality speech recording and apply <code>Mp3Compression</code> with a bitrate of 32 kbps:</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/mp3_compression/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import Mp3Compression\n\ntransform = Mp3Compression(\n    min_bitrate=16,\n    max_bitrate=96,\n    backend=\"fast-mp3-augment\",\n    preserve_delay=False,\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=48000)\n</code></pre>"},{"location":"waveform_transforms/mp3_compression/#mp3compression-api","title":"Mp3Compression API","text":"<code>min_bitrate</code>: <code>int</code> \u2022 unit: kbps \u2022 range: [8, <code>max_bitrate</code>]  Default: <code>8</code>. Minimum bitrate in kbps <code>max_bitrate</code>: <code>int</code> \u2022 unit: kbps \u2022 range: [<code>min_bitrate</code>, 320]  Default: <code>64</code>. Maximum bitrate in kbps <code>backend</code>: <code>str</code> \u2022 choices: <code>\"fast-mp3-augment\"</code>, <code>\"pydub\"</code>, <code>\"lameenc\"</code> <p> Default: <code>\"fast-mp3-augment\"</code>.</p> <ul> <li> <p><code>\"fast-mp3-augment\"</code>: In-memory computation with parallel threads for encoding and decoding. Uses LAME encoder     and minimp3 decoder under the hood. This is the recommended option.</p> </li> <li> <p><code>\"pydub\"</code>: Uses pydub + ffmpeg under the hood. Does not delay the output compared to the input.     It is comparatively slow (writes temporary files to disk). Does not support <code>preserve_delay=True</code>.</p> <p> The <code>\"pydub\"</code> backend is deprecated as of v0.43.0, because pydub appears to have been unmaintained for several years, and depends on audioop, which was deprecated in Python 3.11 and removed in 3.13.</p> </li> <li> <p><code>\"lameenc\"</code>: Slow (writes a temporary file to disk). Introduces encoder + decoder delay, so the output is not in sync     with the input. Does not support <code>preserve_delay=False</code>. Note that bitrates below 32 kbps are only supported for     low sample rates (up to 24000 Hz).</p> <p> The <code>\"lameenc\"</code> backend is deprecated as of v0.42.0, because backend=\"fast-mp3-augment\" is much faster (by a factor of up to 4x) and uses the same encoder, LAME, under the hood.</p> </li> </ul> <code>preserve_delay</code>: <code>bool</code> <p> Default: <code>False</code>.</p> <p>If <code>False</code>, the output length and timing will match the input. If <code>True</code>, include LAME encoder delay + filter delay (a few tens of milliseconds) and padding in the output. This makes the output 1) longer than the input 2) delayed (out of sync) relative to the input</p> <p>Normally, it makes sense to set <code>preserve_delay</code> to <code>False</code>, but if you want outputs that include the short, almost silent part in the beginning, you here have the option to get that.</p> <code>quality</code>: <code>int</code> \u2022 range: [0, 9] <p> Default: <code>7</code>. LAME-specific parameter (between 0 and 9) that controls a trade-off between audio quality and speed: 0: higher quality audio at the cost of slower processing 9: faster processing at the cost of lower quality audio</p> <p>Note: If using <code>backend=\"pydub\"</code>, this parameter gets silently ignored.</p> <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/mp3_compression/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/mp3_compression.py </p>"},{"location":"waveform_transforms/normalize/","title":"<code>Normalize</code>","text":"<p>Added in v0.6.0</p> <p>Apply a constant amount of gain, so that highest signal level present in the sound becomes 0 dBFS, i.e. the loudest level allowed if all samples must be between -1 and 1. Also known as peak normalization.</p>"},{"location":"waveform_transforms/normalize/#normalize-api","title":"Normalize API","text":"<code>apply_to</code>: <code>str</code> \u2022 choices: <code>\"all\"</code>, <code>\"only_too_loud_sounds\"</code> <p> Default: <code>\"all\"</code>. Defines the criterion for applying the transform.</p> <ul> <li><code>\"all\"</code>: Apply peak normalization to all inputs</li> <li><code>\"only_too_loud_sounds\"</code>: Apply peak normalization only to inputs where the maximum absolute peak is greater than 1</li> </ul> <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/normalize/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/normalize.py </p>"},{"location":"waveform_transforms/padding/","title":"<code>Padding</code>","text":"<p>Added in v0.23.0</p> <p>Apply padding to the audio signal by taking a fraction of the start or end and replacing that portion with padding. This can be useful for training ML models on padded inputs.</p>"},{"location":"waveform_transforms/padding/#padding-api","title":"Padding API","text":"<code>mode</code>: <code>str</code> \u2022 choices: <code>\"silence\"</code>, <code>\"wrap\"</code>, <code>\"reflect\"</code>  Default: <code>\"silence\"</code>. Padding mode. <code>min_fraction</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.01</code>. Minimum fraction of the signal duration to be padded. <code>max_fraction</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.7</code>. Maximum fraction of the signal duration to be padded. <code>pad_section</code>: <code>str</code> \u2022 choices: <code>\"start\"</code>, <code>\"end\"</code>  Default: <code>\"end\"</code>. Which part of the signal should be replaced with padding. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/padding/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/padding.py </p>"},{"location":"waveform_transforms/peaking_filter/","title":"<code>PeakingFilter</code>","text":"<p>Added in v0.21.0</p> <p>Add a biquad peaking filter transform</p>"},{"location":"waveform_transforms/peaking_filter/#peakingfilter-api","title":"PeakingFilter API","text":"<code>min_center_freq</code>: <code>float</code> \u2022 unit: hertz \u2022 range: [0.0, \u221e)  Default: <code>50.0</code>. The minimum center frequency of the peaking filter <code>max_center_freq</code>: <code>float</code> \u2022 unit: hertz \u2022 range: [0.0, \u221e)  Default: <code>7500.0</code>. The maximum center frequency of the peaking filter <code>min_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-24.0</code>. The minimum gain at center frequency <code>max_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>24.0</code>. The maximum gain at center frequency <code>min_q</code>: <code>float</code> \u2022 range: [0.0, \u221e)  Default: <code>0.5</code>. The minimum quality factor Q. The higher the Q, the steeper the transition band will be. <code>max_q</code>: <code>float</code> \u2022 range: [0.0, \u221e)  Default: <code>5.0</code>. The maximum quality factor Q. The higher the Q, the steeper the transition band will be. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/peaking_filter/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/peaking_filter.py </p>"},{"location":"waveform_transforms/pitch_shift/","title":"<code>PitchShift</code>","text":"<p>Added in v0.4.0</p> <p>Pitch shift the sound up or down without changing the tempo.</p> <p>You can choose between <code>method=\"signalsmith_stretch\"</code> and <code>method=\"librosa_phase_vocoder\"</code>. If you need other pitch shifting methods, consider the following alternatives:</p> <ul> <li>Rubber Band library</li> <li>https://github.com/KAIST-MACLab/PyTSMod</li> <li>https://github.com/vinusankars/ESOLA</li> </ul>"},{"location":"waveform_transforms/pitch_shift/#input-output-example","title":"Input-output example","text":"<p>Here we pitch down a piano recording by 4 semitones, using the <code>signalsmith_stretch</code> method:</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/pitch_shift/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import PitchShift\n\ntransform = PitchShift(\n    min_semitones=-5.0,\n    max_semitones=5.0,\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=44100)\n</code></pre>"},{"location":"waveform_transforms/pitch_shift/#pitchshift-api","title":"PitchShift API","text":"<code>min_semitones</code>: <code>float</code> \u2022 unit: semitones \u2022 range: [-24.0, 24.0]  Default: <code>-4.0</code>. Minimum semitones to shift. A negative number means shift down. <code>max_semitones</code>: <code>float</code> \u2022 unit: semitones \u2022 range: [-24.0, 24.0]  Default: <code>4.0</code>. Maximum semitones to shift. A positive number means shift up. <code>backend</code>: <code>str</code> \u2022 choices: <code>\"librosa_phase_vocoder\"</code>, <code>\"signalsmith_stretch\"</code> <p> Default: <code>\"signalsmith_stretch\"</code>.</p> <ul> <li><code>\"signalsmith_stretch\"</code>: Use signalsmith-stretch. It is 50-100% faster than librosa_phase_vocoder, and provides significantly higher perceived audio quality.</li> <li><code>\"librosa_phase_vocoder\"</code>: Use librosa.effects.pitch_shift, which performs time stretching (by phase vocoding) followed by resampling. Pro: Supports any number of channels. Con: phase vocoding can significantly degrade the audio quality by \"smearing\" transient sounds, altering the timbre of harmonic sounds, and distorting pitch modulations. This may result in a loss of sharpness, clarity, or naturalness in the transformed audio.</li> </ul> <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/pitch_shift/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/pitch_shift.py </p>"},{"location":"waveform_transforms/polarity_inversion/","title":"<code>PolarityInversion</code>","text":"<p>Added in v0.11.0</p> <p>Flip the audio samples upside-down, reversing their polarity. In other words, multiply the waveform by -1, so negative values become positive, and vice versa. The result will sound the same compared to the original when played back in isolation. However, when mixed with other audio sources, the result may be different. This waveform inversion technique is sometimes used for audio cancellation or obtaining the difference between two waveforms. In the context of audio data augmentation, this transform can be useful when training phase-aware machine learning models.</p>"},{"location":"waveform_transforms/polarity_inversion/#polarityinversion-api","title":"PolarityInversion API","text":"<code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/polarity_inversion/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/polarity_inversion.py </p>"},{"location":"waveform_transforms/post_gain/","title":"<code>PostGain</code>","text":"<p>Added in v0.31.0</p> <p>Gain up or down the audio after the given transform (or set of transforms) has processed the audio. There are several methods that determine how the audio should be gained. <code>PostGain</code> can be useful for compensating for any gain differences introduced by a (set of) transform(s), or for preventing clipping in the output.</p>"},{"location":"waveform_transforms/post_gain/#postgain-api","title":"PostGain API","text":"<code>transform</code>: <code>Callable[[NDArray[np.float32], int], NDArray[np.float32]]</code>  A callable to be applied. It should input samples (ndarray), sample_rate (int) and optionally some user-defined keyword arguments. <code>method</code>: <code>str</code> \u2022 choices: <code>\"same_rms\"</code>, <code>\"same_lufs\"</code> or <code>\"peak_normalize_always\"</code> <p> This parameter defines the method for choosing the post gain amount.</p> <ul> <li><code>\"same_rms\"</code>: The sound gets post-gained so that the RMS (Root Mean Square) of     the output matches the RMS of the input.</li> <li><code>\"same_lufs\"</code>: The sound gets post-gained so that the LUFS (Loudness Units Full Scale) of     the output matches the LUFS of the input.</li> <li><code>\"peak_normalize_always\"</code>: The sound gets peak normalized (gained up or down so     that the absolute value of the most extreme sample in the output is 1.0)</li> <li><code>\"peak_normalize_if_too_loud\"</code>: The sound gets peak normalized if it is too     loud (max absolute value greater than 1.0). This option can be useful for     avoiding clipping.</li> </ul>"},{"location":"waveform_transforms/post_gain/#source-code","title":"Source code","text":"<p>audiomentations/core/post_gain.py </p>"},{"location":"waveform_transforms/repeat_part/","title":"<code>RepeatPart</code>","text":"<p>Added in v0.32.0</p> <p>Select a subsection (or \"part\") of the audio and repeat that part a number of times. This can be useful when simulating scenarios where a short audio snippet gets repeated, for example:</p> <ul> <li>Repetitions of some musical note or sound in a rhythmical way</li> <li>A person stutters or says the same word (with variations) multiple times in a row</li> <li>A mechanical noise with periodic repetitions</li> <li>A \"skip in the record\" or a \"stuck needle\" effect, reminiscent of vinyl records or   CDs when they repeatedly play a short section due to a scratch or other   imperfection.</li> <li>Digital audio glitches, such as a buffer underrun in video games,   where the current audio frame gets looped continuously due to system overloads   or a software crash.</li> </ul> <p>Note that the length of inputs you give it must be compatible with the part duration range and crossfade duration. If you give it an input audio array that is too short, a <code>UserWarning</code> will be raised and no operation is applied to the signal.</p>"},{"location":"waveform_transforms/repeat_part/#input-output-example","title":"Input-output example","text":"<p>In this speech example, the audio was transformed with</p> <ul> <li>a part duration of approximately 0.4 seconds</li> <li>\"insert\" mode. In this mode, the output becomes longer than the input.</li> <li>a <code>SevenBandParametricEQ</code> part transform. This is why each repeat in the output   has a different timbre.</li> </ul> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/repeat_part/#usage-examples","title":"Usage examples","text":"Insert modeReplace mode <pre><code>from audiomentations import RepeatPart\n\ntransform = RepeatPart(mode=\"insert\", p=1.0)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre> <pre><code>from audiomentations import RepeatPart\n\ntransform = RepeatPart(mode=\"replace\", p=1.0)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/repeat_part/#repeatpart-api","title":"RepeatPart API","text":"<code>min_repeats</code>: <code>int</code> \u2022 range: [1, <code>max_repeats</code>]  Default: <code>1</code>. Minimum number of times a selected audio   segment should be repeated in addition to the original. For instance, if the selected   number of repeats is 1, the selected segment will be followed by one repeat. <code>max_repeats</code>: <code>int</code> \u2022 range: [<code>min_repeats</code>, \u221e)  Default: <code>3</code>. Maximum number of times a selected audio   segment can be repeated in addition to the original <code>min_part_duration</code>: <code>float</code> \u2022 unit: seconds \u2022 range: [0.00025, <code>max_part_duration</code>]  Default: <code>0.25</code>. Minimum duration (in seconds) of the audio   segment that can be selected for repetition. <code>max_part_duration</code>: <code>float</code> \u2022 unit: seconds \u2022 range: [<code>min_part_duration</code>, \u221e)  Default: <code>1.2</code>. Maximum duration (in seconds) of the audio   segment that can be selected for repetition. <code>mode</code>: <code>str</code> \u2022 choices: <code>\"insert\"</code>, <code>\"replace\"</code> <p> Default: <code>\"insert\"</code>. This parameter has two options:</p> <ul> <li><code>\"insert\"</code>: Insert the repeat(s), making the array longer. After the last   repeat there will be the last part of the original audio, offset in time   compared to the input array.</li> <li><code>\"replace\"</code>: Have the repeats replace (as in overwrite) the original audio.   Any remaining part at the end (if not overwritten by repeats) will be   left untouched without offset. The length of the output array is the   same as the input array.</li> </ul> <code>crossfade_duration</code>: <code>float</code> \u2022 unit: seconds \u2022 range: 0.0 or [0.00025, \u221e)  Default: <code>0.005</code>. Duration for crossfading between repeated   parts as well as potentially from the original audio to the repeats and back.   The crossfades will be equal-energy or equal-gain depending on the audio and/or the   chosen parameters of the transform. The crossfading feature can be used to smooth   transitions and avoid abrupt changes, which can lead to impulses/clicks in the audio.   If you know what you're doing, and impulses/clicks are desired for your use case,   you can disable the crossfading by setting this value to <code>0.0</code>. <code>part_transform</code>: <code>Optional[Callable[[NDArray[np.float32], int], NDArray[np.float32]]]</code>  An optional callable (audiomentations transform) that   gets applied individually to each repeat. This can be used to make each   repeat slightly different from the previous one. Note that a <code>part_transform</code>   that makes the part shorter is only supported if the transformed part is at   least two times the crossfade duration. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/repeat_part/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/repeat_part.py </p>"},{"location":"waveform_transforms/resample/","title":"<code>Resample</code>","text":"<p>Added in v0.8.0</p> <p>Resample signal using librosa.core.resample</p> <p>To do downsampling only, set both minimum and maximum sampling rate lower than original sampling rate. Conversely, to perform upsampling only, set both rates higher than the original sampling rate.</p>"},{"location":"waveform_transforms/resample/#resample-api","title":"Resample API","text":"<code>min_sample_rate</code>: <code>int</code> \u2022 unit: Hz  Default: <code>8000</code>. The minimum sample rate <code>max_sample_rate</code>: <code>int</code> \u2022 unit: Hz  Default: <code>44100</code>. The maximum sample rate <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/resample/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/resample.py </p>"},{"location":"waveform_transforms/reverse/","title":"<code>Reverse</code>","text":"<p>Added in v0.18.0</p> <p>Reverse the audio, also known as time inversion. Inversion of an audio track along its time axis is analogous to the random flip of an image, an augmentation technique widely used in the visual domain. This can be relevant in the context of audio classification. It was successfully applied in the paper AudioCLIP: Extending CLIP to Image, Text and Audio .</p> <p>Note for PyTorch users This transform returns a negative-stride array for efficiency. If you intend to convert the reversed waveform to a PyTorch tensor via <code>torch.from_numpy()</code>, you must make the array contiguous first: <pre><code>reversed_waveform = transform(my_waveform_ndarray, sample_rate=44100)\nreversed_waveform = reversed_waveform.copy()  # or use np.ascontiguousarray\ntensor = torch.from_numpy(reversed_waveform)\n</code></pre></p>"},{"location":"waveform_transforms/reverse/#input-output-example","title":"Input-output example","text":"<p>In this example, we reverse a speech recording</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/reverse/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import Reverse\n\ntransform = Reverse(p=1.0)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=44100)\n</code></pre>"},{"location":"waveform_transforms/reverse/#reverse-api","title":"Reverse API","text":"<code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/reverse/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/reverse.py </p>"},{"location":"waveform_transforms/room_simulator/","title":"<code>RoomSimulator</code>","text":"<p>Added in v0.23.0</p> <p>A ShoeBox Room Simulator. Simulates a cuboid of parametrized size and average surface absorption coefficient. It also includes a source and microphones in parametrized locations.</p> <p>Use it when you need a large number of synthetic room impulse responses with specific configuration characteristics or simply to quickly add reverb for augmentation purposes.</p>"},{"location":"waveform_transforms/room_simulator/#roomsimulator-api","title":"RoomSimulator API","text":"<code>min_size_x</code>: <code>float</code> \u2022 unit: meters  Default: <code>3.6</code>. Minimum width (x coordinate) of the room in meters <code>max_size_x</code>: <code>float</code> \u2022 unit: meters  Default: <code>5.6</code>. Maximum width of the room in meters <code>min_size_y</code>: <code>float</code> \u2022 unit: meters  Default: <code>3.6</code>. Minimum depth (y coordinate) of the room in meters <code>max_size_y</code>: <code>float</code> \u2022 unit: meters  Default: <code>3.9</code>. Maximum depth of the room in meters <code>min_size_z</code>: <code>float</code> \u2022 unit: meters  Default: <code>2.4</code>. Minimum height (z coordinate) of the room in meters <code>max_size_z</code>: <code>float</code> \u2022 unit: meters  Default: <code>3.0</code>. Maximum height of the room in meters <code>min_absorption_value</code>: <code>float</code> <p> Default: <code>0.075</code>. Minimum absorption coefficient value. When <code>calculation_mode</code> is <code>\"absorption\"</code> it will set the given coefficient value for the surfaces of the room (walls, ceilings, and floor). This coefficient takes values between 0 (fully reflective surface) and 1 (fully absorbing surface).</p> <p>Example values (may differ!):</p> Environment Coefficient value Studio with acoustic panels &gt; 0.40 Office / Library ~ 0.15 Factory ~ 0.05 <code>max_absorption_value</code>: <code>float</code>  Default: <code>0.4</code>. Maximum absorption coefficient value. See <code>min_absorption_value</code> for more info. <code>min_target_rt60</code>: <code>float</code> \u2022 unit: seconds <p> Default: <code>0.15</code>. Minimum target RT60. RT60 is defined as the measure of the time after the sound source ceases that it takes for the sound pressure level to reduce by 60 dB. When <code>calculation_mode</code> is <code>\"rt60\"</code>, it tries to set the absorption value of the surfaces of the room to achieve a target RT60 (in seconds). Note that this parameter changes only the materials (absorption coefficients) of the surfaces, not the dimension of the rooms.</p> <p>Example values (may differ!):</p> Environment RT60 Recording studio 0.3 s Office 0.5 s Concert hall 1.5 s <code>max_target_rt60</code>: <code>float</code> \u2022 unit: seconds  Default: <code>0.8</code>. Maximum target RT60. See <code>min_target_rt60</code> for more info. <code>min_source_x</code>: <code>float</code> \u2022 unit: meters  Default: <code>0.1</code>. Minimum x location of the source <code>max_source_x</code>: <code>float</code> \u2022 unit: meters  Default: <code>3.5</code>. Maximum x location of the source <code>min_source_y</code>: <code>float</code> \u2022 unit: meters  Default: <code>0.1</code>. Minimum y location of the source <code>max_source_y</code>: <code>float</code> \u2022 unit: meters  Default: <code>2.7</code>. Maximum y location of the source <code>min_source_z</code>: <code>float</code> \u2022 unit: meters  Default: <code>1.0</code>. Minimum z location of the source <code>max_source_z</code>: <code>float</code> \u2022 unit: meters  Default: <code>2.1</code>. Maximum z location of the source <code>min_mic_distance</code>: <code>float</code> \u2022 unit: meters  Default: <code>0.15</code>. Minimum distance of the microphone from the source in meters <code>max_mic_distance</code>: <code>float</code> \u2022 unit: meters  Default: <code>0.35</code>. Maximum distance of the microphone from the source in meters <code>min_mic_azimuth</code>: <code>float</code> \u2022 unit: radians  Default: <code>-math.pi</code>. Minimum azimuth (angle around z axis) of the microphone relative to the source. <code>max_mic_azimuth</code>: <code>float</code> \u2022 unit: radians  Default: <code>math.pi</code>. Maximum azimuth (angle around z axis) of the microphone relative to the source. <code>min_mic_elevation</code>: <code>float</code> \u2022 unit: radians  Default: <code>-math.pi</code>. Minimum elevation of the microphone relative to the source, in radians. <code>max_mic_elevation</code>: <code>float</code> \u2022 unit: radians  Default: <code>math.pi</code>. Maximum elevation of the microphone relative to the source, in radians. <code>calculation_mode</code>: <code>str</code> \u2022 choices: <code>\"rt60\"</code>, <code>\"absorption\"</code>  Default: <code>\"absorption\"</code>. When set to <code>\"absorption\"</code>, it will create the room with surfaces based on <code>min_absorption_value</code> and <code>max_absorption_value</code>. If set to <code>\"rt60\"</code>, it will try to assign surface materials that lead to a room impulse response with the target RT60 given by <code>min_target_rt60</code> and <code>max_target_rt60</code> <code>use_ray_tracing</code>: <code>bool</code>  Default: <code>True</code>. Whether to use ray_tracing or not (slower but much more accurate). Disable this if you prioritize speed over accuracy. <code>max_order</code>: <code>int</code> \u2022 range: [1, \u221e) <p> Default: <code>1</code>. Maximum order of reflections for the Image Source Model. E.g. a value of 1 will only add first order reflections while a value of 4-12 will add a diffuse reverberation tail.</p> <p>Warning</p> <p>Setting this higher than 11-12 can significantly slow down the augmentation process when <code>calculation_mode=\"rt60\"</code>. </p> <p>Tip</p> <p>When using <code>calculation_mode=\"rt60\"</code>, keep it around <code>3-4</code>.</p> <code>leave_length_unchanged</code>: <code>bool</code>  Default: <code>False</code>. When set to True, the tail of the sound (e.g. reverb at the end) will be chopped off so that the length of the output is equal to the length of the input. <code>padding</code>: <code>float</code> \u2022 unit: meters  Default: <code>0.1</code>. Minimum distance in meters between source or mic and the room walls, floor or ceiling. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform. <code>ray_tracing_options</code>: <code>Optional[Dict]</code>  Default: <code>None</code>. Options for the ray tracer. See <code>set_ray_tracing</code> here: https://github.com/LCAV/pyroomacoustics/blob/master/pyroomacoustics/room.py"},{"location":"waveform_transforms/room_simulator/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/room_simulator.py </p>"},{"location":"waveform_transforms/seven_band_parametric_eq/","title":"<code>SevenBandParametricEQ</code>","text":"<p>Added in v0.24.0</p> <p>Adjust the volume of different frequency bands. This transform is a 7-band parametric equalizer - a combination of one low shelf filter, five peaking filters and one high shelf filter, all with randomized gains, Q values and center frequencies.</p> <p>Because this transform changes the timbre but keeps the overall \"class\" of the sound the same (depending on the application), it can be used for data augmentation to make ML models more robust to various frequency spectra. Many things can affect the spectrum, for example:</p> <ul> <li>the nature and quality of the sound source</li> <li>room acoustics</li> <li>any objects between the microphone and the sound source</li> <li>microphone type or model</li> <li>the distance between the sound source and the microphone</li> </ul> <p>The seven bands have center frequencies picked in the following ranges (min-max):</p> <ul> <li>42-95 Hz</li> <li>91-204 Hz</li> <li>196-441 Hz</li> <li>421-948 Hz</li> <li>909-2045 Hz</li> <li>1957-4404 Hz</li> <li>4216-9486 Hz</li> </ul>"},{"location":"waveform_transforms/seven_band_parametric_eq/#sevenbandparametriceq-api","title":"SevenBandParametricEQ API","text":"<code>min_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>-12.0</code>. Minimum number of dB to cut or boost a band <code>max_gain_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>12.0</code>. Maximum number of dB to cut or boost a band <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/seven_band_parametric_eq/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/seven_band_parametric_eq.py </p>"},{"location":"waveform_transforms/shift/","title":"<code>Shift</code>","text":"<p>Added in v0.5.0</p> <p>Shift the samples forwards or backwards, with or without rollover</p>"},{"location":"waveform_transforms/shift/#shift-api","title":"Shift API","text":"<p> This only applies to version 0.33.0 and newer. If you are using an older version, you should consider upgrading. Or if you really want to keep using the old version, you can check the \"Old Shift API (&lt;=v0.32.0)\" section below</p> <code>min_shift</code>: <code>float | int</code>  Default: <code>-0.5</code>. Minimum amount of shifting in time. See also <code>shift_unit</code>. <code>max_shift</code>: <code>float | int</code>  Default: <code>0.5</code>. Maximum amount of shifting in time. See also <code>shift_unit</code>. <code>shift_unit</code>: <code>str</code> \u2022 choices: <code>\"fraction\"</code>, <code>\"samples\"</code>, <code>\"seconds\"</code> <p> Default: <code>\"fraction\"</code> Defines the unit of the value of <code>min_shift</code> and <code>max_shift</code>.</p> <ul> <li><code>\"fraction\"</code>: Fraction of the total sound length</li> <li><code>\"samples\"</code>: Number of audio samples</li> <li><code>\"seconds\"</code>: Number of seconds</li> </ul> <code>rollover</code>: <code>bool</code>  Default: <code>True</code>. When set to <code>True</code>, samples that roll beyond the first or last position are re-introduced at the last or first. When set to <code>False</code>, samples that roll beyond the first or last position are discarded. In other words, <code>rollover=False</code> results in an empty space (with zeroes). <code>fade_duration</code>: <code>float</code> \u2022 unit: seconds \u2022 range: 0.0 or [0.00025, \u221e)  Default: <code>0.005</code>. If you set this to a positive number, there will be a fade in and/or out at the \"stitch\" (that was the start or the end of the audio before the shift). This can smooth out an unwanted abrupt change between two consecutive samples (which sounds like a transient/click/pop). This parameter denotes the duration of the fade in seconds. To disable the fading feature, set this parameter to 0.0. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/shift/#old-shift-api-v0320","title":"Old Shift API (&lt;=v0.32.0)","text":"<p> This only applies to version 0.32.0 and older</p> <code>min_fraction</code>: <code>float</code> \u2022 range: [-1, 1]  Default: <code>-0.5</code>. Minimum fraction of total sound length to shift. <code>max_fraction</code>: <code>float</code> \u2022 range: [-1, 1]  Default: <code>0.5</code>. Maximum fraction of total sound length to shift. <code>rollover</code>: <code>bool</code>  Default: <code>True</code>. When set to <code>True</code>, samples that roll beyond the last position are re-introduced at the first position, and samples that roll beyond the first position are re-introduced at the last position. When set to <code>False</code>, samples that roll beyond the first or last position are discarded. In other words, <code>rollover=False</code> results in an empty space (with zeroes). <code>fade</code>: <code>bool</code>  Default: <code>False</code>. When set to <code>True</code>, there will be a short fade in and/or out at the \"stitch\" (that was the start or the end of the audio before the shift). This can smooth out an unwanted abrupt change between two consecutive samples, which would otherwise sound like a transient/click/pop. <code>fade_duration</code>: <code>float</code> \u2022 unit: seconds  Default: <code>0.01</code>. If <code>fade=True</code>, then this is the duration of the fade in seconds. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/shift/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/shift.py </p>"},{"location":"waveform_transforms/tanh_distortion/","title":"<code>TanhDistortion</code>","text":"<p>Added in v0.19.0</p> <p>Apply tanh (hyperbolic tangent) distortion to the audio. This technique is sometimes used for adding distortion to guitar recordings. The tanh() function can give a rounded \"soft clipping\" kind of distortion, and the distortion amount is proportional to the loudness of the input and the pre-gain. Tanh is symmetric, so the positive and negative parts of the signal are squashed in the same way. This transform can be useful as data augmentation because it adds harmonics. In other words, it changes the timbre of the sound.</p> <p>See this page for examples: http://gdsp.hf.ntnu.no/lessons/3/17/</p>"},{"location":"waveform_transforms/tanh_distortion/#input-output-example","title":"Input-output example","text":"<p>In this example, we apply tanh distortion with the distortion amount (think of it as a knob that goes from 0 to 1) set to 0.25</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/tanh_distortion/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import TanhDistortion\n\ntransform = TanhDistortion(\n    min_distortion=0.01,\n    max_distortion=0.7,\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/tanh_distortion/#tanhdistortion-api","title":"TanhDistortion API","text":"<code>min_distortion</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.01</code>. Minimum \"amount\" of distortion to apply to the signal. <code>max_distortion</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.7</code>. Maximum \"amount\" of distortion to apply to the signal. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/tanh_distortion/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/tanh_distortion.py </p>"},{"location":"waveform_transforms/time_mask/","title":"<code>TimeMask</code>","text":"<p>Added in v0.7.0</p> <p>Make a randomly chosen part of the audio silent. Inspired by https://arxiv.org/pdf/1904.08779.pdf</p>"},{"location":"waveform_transforms/time_mask/#input-output-example","title":"Input-output example","text":"<p>Here we silence a part of a speech recording.</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/time_mask/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import TimeMask\n\ntransform = TimeMask(\n    min_band_part=0.1,\n    max_band_part=0.15,\n    p=1.0,\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/time_mask/#timemask-api","title":"TimeMask API","text":"<code>min_band_part</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.01</code>. Minimum length of the silent part as a fraction of the total sound length. <code>max_band_part</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.2</code>. Maximum length of the silent part as a fraction of the total sound length. <code>fade_duration</code>: <code>float</code> \u2022 unit: seconds \u2022 range: 0.0 or [0.00025, \u221e)  Default: <code>0.005</code>. Duration of the fade-in and fade-out applied at the edges of the silent region to smooth transitions and avoid abrupt changes, which can otherwise produce impulses or clicks in the audio. If you need hard edges or clicks, set this to <code>0.0</code> to disable fading. Positive values must be at least 0.00025. <code>mask_location</code>: <code>str</code> \u2022 choices: <code>\"start\"</code>, <code>\"end\"</code>, <code>\"random\"</code> <p> Default: <code>random</code>. Where to place the silent region.</p> <ul> <li><code>\"start\"</code>: silence begins at index 0</li> <li><code>\"end\"</code>: silence ends at the last sample</li> <li><code>\"random\"</code>: silence starts at a random position</li> </ul> <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/time_mask/#old-timemask-api-v0400","title":"Old TimeMask API (&lt;=v0.40.0)","text":"<p> This only applies to version 0.40.0 and older</p> <code>fade</code>: <code>bool</code>  Default: <code>False</code>. When set to <code>True</code>, a linear fade-in and fade-out is added to the silent part. This can smooth out unwanted abrupt changes between consecutive samples, which might otherwise sound like transients/clicks/pops."},{"location":"waveform_transforms/time_mask/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/time_mask.py </p>"},{"location":"waveform_transforms/time_stretch/","title":"<code>TimeStretch</code>","text":"<p>Added in v0.2.0</p> <p>Change the speed or duration of the signal without changing the pitch. This transform lets you choose between <code>method=\"signalsmith_stretch\"</code> and <code>method=\"librosa_phase_vocoder\"</code>. If you need other time stretching methods, consider the following alternatives:</p> <ul> <li>atempo in ffmpeg</li> <li>Rubber Band library</li> <li>https://github.com/KAIST-MACLab/PyTSMod</li> <li>https://github.com/vinusankars/ESOLA</li> </ul>"},{"location":"waveform_transforms/time_stretch/#input-output-example","title":"Input-output example","text":"<p>In this example we speed up a sound by 25% (i.e. a rate of 1.25), using the <code>signalsmith_stretch</code> method:</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/time_stretch/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import TimeStretch\n\ntransform = TimeStretch(\n    min_rate=0.8,\n    max_rate=1.25,\n    leave_length_unchanged=True,\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/time_stretch/#timestretch-api","title":"TimeStretch API","text":"<code>min_rate</code>: <code>float</code> \u2022 range: [0.1, 10.0]  Default: <code>0.8</code>. Minimum time-stretch rate. Values less than 1.0 slow down the audio (reduce the playback speed). <code>max_rate</code>: <code>float</code> \u2022 range: [0.1, 10.0]  Default: <code>1.25</code>. Maximum time-stretch rate. Values greater than 1.0 speed up the audio (increase the playback speed). <code>leave_length_unchanged</code>: <code>bool</code>  Default: <code>True</code>.  If <code>True</code>, the output audio will have the same duration as the input audio. If <code>False</code>, the duration of the output audio will be altered by the time-stretch rate. <code>method</code>: <code>str</code> \u2022 choices: <code>\"librosa_phase_vocoder\"</code>, <code>\"signalsmith_stretch\"</code> <p> Default: <code>\"signalsmith_stretch\"</code>.</p> <ul> <li><code>\"signalsmith_stretch\"</code>: Use signalsmith-stretch. It is 50-100% faster than librosa_phase_vocoder, and provides significantly higher perceived audio quality.</li> <li><code>\"librosa_phase_vocoder\"</code>: Use librosa.effects.time_stretch. Pro: Supports any number of channels. Con: phase vocoding can significantly degrade the audio quality by \"smearing\" transient sounds, altering the timbre of harmonic sounds, and distorting pitch modulations. This may result in a loss of sharpness, clarity, or naturalness in the transformed audio.</li> </ul> <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/time_stretch/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/time_stretch.py </p>"},{"location":"waveform_transforms/trim/","title":"<code>Trim</code>","text":"<p>Added in v0.7.0</p> <p>Trim leading and trailing silence from an audio signal using <code>librosa.effects.trim</code>. It considers threshold (in Decibels) below reference defined in parameter <code>top_db</code> as silence.</p>"},{"location":"waveform_transforms/trim/#input-output-example","title":"Input-output example","text":"<p>In this example we remove silence from the start and end, using the default top_db parameter value</p> <p></p> Input sound Transformed sound"},{"location":"waveform_transforms/trim/#usage-example","title":"Usage example","text":"<pre><code>from audiomentations import Trim\n\ntransform = Trim(\n    top_db=30.0,\n    p=1.0\n)\n\naugmented_sound = transform(my_waveform_ndarray, sample_rate=16000)\n</code></pre>"},{"location":"waveform_transforms/trim/#trim-api","title":"Trim API","text":"<code>top_db</code>: <code>float</code> \u2022 unit: Decibel  Default: <code>30.0</code>. The threshold value (in Decibels) below which to consider silence and trim. <code>p</code>: <code>float</code> \u2022 range: [0.0, 1.0]  Default: <code>0.5</code>. The probability of applying this transform."},{"location":"waveform_transforms/trim/#source-code","title":"Source code","text":"<p>audiomentations/augmentations/trim.py </p>"}]}